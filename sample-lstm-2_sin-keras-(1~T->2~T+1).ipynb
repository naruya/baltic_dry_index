{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- https://qiita.com/sasayabaku/items/b7872a3b8acc7d6261bf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(201,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 600x200 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Activation\n",
    "from keras.layers.recurrent import LSTM\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "def sin(x, T=100):\n",
    "    return np.sin(2.0 * np.pi * x / T)\n",
    "\n",
    "# sin波にノイズを付与する\n",
    "def toy_problem(T=100, ampl=0.05):\n",
    "    x = np.arange(0, 2 * T + 1)\n",
    "    noise = ampl * np.random.uniform(low=-1.0, high=1.0, size=len(x))\n",
    "    return sin(x) + noise\n",
    "\n",
    "f = toy_problem()\n",
    "print(f.shape)\n",
    "plt.figure(figsize=(6,2));plt.plot(f);plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- aaa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(176, 25, 1) (176, 25, 1)\n"
     ]
    }
   ],
   "source": [
    "def make_dataset(low_data, n_prev=100):\n",
    "\n",
    "    data, target = [], []\n",
    "    maxlen = 25\n",
    "\n",
    "    for i in range(len(low_data)-maxlen):\n",
    "        data.append(low_data[i:i + maxlen]) # x (25フレーム切り取ってくる)\n",
    "        target.append(low_data[i+1:i + maxlen+1]) # y (xの1フレーム先)\n",
    "\n",
    "    re_data = np.array(data).reshape(len(data), maxlen, 1)\n",
    "    re_target = np.array(target).reshape(len(data), maxlen, 1)\n",
    "\n",
    "    return re_data, re_target\n",
    "\n",
    "\n",
    "#g -> 学習データ，h -> 学習ラベル\n",
    "g, h = make_dataset(f)\n",
    "print(g.shape, h.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1 (LSTM)                (None, 25, 8)             320       \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 25, 1)             9         \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 25, 1)             0         \n",
      "=================================================================\n",
      "Total params: 329\n",
      "Trainable params: 329\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "length_of_sequence = g.shape[1] # 25\n",
    "in_out_neurons = 1\n",
    "n_hidden = 8\n",
    "\n",
    "model = Sequential()\n",
    "model.add(LSTM(n_hidden, batch_input_shape=(None, length_of_sequence, in_out_neurons), return_sequences=True))\n",
    "model.add(Dense(in_out_neurons))\n",
    "model.add(Activation(\"linear\"))\n",
    "optimizer = Adam()\n",
    "model.compile(loss=\"mean_squared_error\", optimizer=optimizer)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 158 samples, validate on 18 samples\n",
      "Epoch 1/1000\n",
      "158/158 [==============================] - 1s 4ms/step - loss: 1.0606 - val_loss: 1.5411\n",
      "Epoch 2/1000\n",
      "158/158 [==============================] - 0s 157us/step - loss: 1.0500 - val_loss: 1.5354\n",
      "Epoch 3/1000\n",
      "158/158 [==============================] - 0s 123us/step - loss: 1.0397 - val_loss: 1.5302\n",
      "Epoch 4/1000\n",
      "158/158 [==============================] - 0s 141us/step - loss: 1.0305 - val_loss: 1.5243\n",
      "Epoch 5/1000\n",
      "158/158 [==============================] - 0s 130us/step - loss: 1.0205 - val_loss: 1.5184\n",
      "Epoch 6/1000\n",
      "158/158 [==============================] - 0s 153us/step - loss: 1.0107 - val_loss: 1.5123\n",
      "Epoch 7/1000\n",
      "158/158 [==============================] - 0s 140us/step - loss: 1.0011 - val_loss: 1.5061\n",
      "Epoch 8/1000\n",
      "158/158 [==============================] - 0s 139us/step - loss: 0.9917 - val_loss: 1.4998\n",
      "Epoch 9/1000\n",
      "158/158 [==============================] - 0s 130us/step - loss: 0.9824 - val_loss: 1.4932\n",
      "Epoch 10/1000\n",
      "158/158 [==============================] - 0s 147us/step - loss: 0.9733 - val_loss: 1.4866\n",
      "Epoch 11/1000\n",
      "158/158 [==============================] - 0s 116us/step - loss: 0.9643 - val_loss: 1.4798\n",
      "Epoch 12/1000\n",
      "158/158 [==============================] - 0s 136us/step - loss: 0.9555 - val_loss: 1.4729\n",
      "Epoch 13/1000\n",
      "158/158 [==============================] - 0s 142us/step - loss: 0.9469 - val_loss: 1.4659\n",
      "Epoch 14/1000\n",
      "158/158 [==============================] - 0s 149us/step - loss: 0.9383 - val_loss: 1.4589\n",
      "Epoch 15/1000\n",
      "158/158 [==============================] - 0s 174us/step - loss: 0.9299 - val_loss: 1.4519\n",
      "Epoch 16/1000\n",
      "158/158 [==============================] - 0s 159us/step - loss: 0.9217 - val_loss: 1.4447\n",
      "Epoch 17/1000\n",
      "158/158 [==============================] - 0s 133us/step - loss: 0.9135 - val_loss: 1.4376\n",
      "Epoch 18/1000\n",
      "158/158 [==============================] - 0s 194us/step - loss: 0.9055 - val_loss: 1.4304\n",
      "Epoch 19/1000\n",
      "158/158 [==============================] - 0s 165us/step - loss: 0.8976 - val_loss: 1.4232\n",
      "Epoch 20/1000\n",
      "158/158 [==============================] - 0s 138us/step - loss: 0.8899 - val_loss: 1.4161\n",
      "Epoch 21/1000\n",
      "158/158 [==============================] - 0s 151us/step - loss: 0.8823 - val_loss: 1.4089\n",
      "Epoch 22/1000\n",
      "158/158 [==============================] - 0s 144us/step - loss: 0.8748 - val_loss: 1.4017\n",
      "Epoch 23/1000\n",
      "158/158 [==============================] - 0s 137us/step - loss: 0.8674 - val_loss: 1.3945\n",
      "Epoch 24/1000\n",
      "158/158 [==============================] - 0s 141us/step - loss: 0.8601 - val_loss: 1.3873\n",
      "Epoch 25/1000\n",
      "158/158 [==============================] - 0s 134us/step - loss: 0.8529 - val_loss: 1.3801\n",
      "Epoch 26/1000\n",
      "158/158 [==============================] - 0s 112us/step - loss: 0.8458 - val_loss: 1.3729\n",
      "Epoch 27/1000\n",
      "158/158 [==============================] - 0s 122us/step - loss: 0.8388 - val_loss: 1.3657\n",
      "Epoch 28/1000\n",
      "158/158 [==============================] - 0s 115us/step - loss: 0.8319 - val_loss: 1.3586\n",
      "Epoch 29/1000\n",
      "158/158 [==============================] - 0s 102us/step - loss: 0.8251 - val_loss: 1.3514\n",
      "Epoch 30/1000\n",
      "158/158 [==============================] - 0s 126us/step - loss: 0.8184 - val_loss: 1.3442\n",
      "Epoch 31/1000\n",
      "158/158 [==============================] - 0s 109us/step - loss: 0.8118 - val_loss: 1.3371\n",
      "Epoch 32/1000\n",
      "158/158 [==============================] - 0s 100us/step - loss: 0.8053 - val_loss: 1.3299\n",
      "Epoch 33/1000\n",
      "158/158 [==============================] - 0s 131us/step - loss: 0.7988 - val_loss: 1.3228\n",
      "Epoch 34/1000\n",
      "158/158 [==============================] - 0s 162us/step - loss: 0.7925 - val_loss: 1.3156\n",
      "Epoch 35/1000\n",
      "158/158 [==============================] - 0s 133us/step - loss: 0.7862 - val_loss: 1.3085\n",
      "Epoch 36/1000\n",
      "158/158 [==============================] - 0s 144us/step - loss: 0.7800 - val_loss: 1.3014\n",
      "Epoch 37/1000\n",
      "158/158 [==============================] - 0s 137us/step - loss: 0.7738 - val_loss: 1.2943\n",
      "Epoch 38/1000\n",
      "158/158 [==============================] - 0s 152us/step - loss: 0.7678 - val_loss: 1.2872\n",
      "Epoch 39/1000\n",
      "158/158 [==============================] - 0s 196us/step - loss: 0.7618 - val_loss: 1.2801\n",
      "Epoch 40/1000\n",
      "158/158 [==============================] - 0s 171us/step - loss: 0.7558 - val_loss: 1.2730\n",
      "Epoch 41/1000\n",
      "158/158 [==============================] - 0s 146us/step - loss: 0.7500 - val_loss: 1.2660\n",
      "Epoch 42/1000\n",
      "158/158 [==============================] - 0s 177us/step - loss: 0.7442 - val_loss: 1.2589\n",
      "Epoch 43/1000\n",
      "158/158 [==============================] - 0s 137us/step - loss: 0.7384 - val_loss: 1.2519\n",
      "Epoch 44/1000\n",
      "158/158 [==============================] - 0s 186us/step - loss: 0.7327 - val_loss: 1.2448\n",
      "Epoch 45/1000\n",
      "158/158 [==============================] - 0s 209us/step - loss: 0.7271 - val_loss: 1.2378\n",
      "Epoch 46/1000\n",
      "158/158 [==============================] - 0s 218us/step - loss: 0.7215 - val_loss: 1.2308\n",
      "Epoch 47/1000\n",
      "158/158 [==============================] - 0s 141us/step - loss: 0.7159 - val_loss: 1.2238\n",
      "Epoch 48/1000\n",
      "158/158 [==============================] - 0s 124us/step - loss: 0.7105 - val_loss: 1.2169\n",
      "Epoch 49/1000\n",
      "158/158 [==============================] - 0s 150us/step - loss: 0.7050 - val_loss: 1.2099\n",
      "Epoch 50/1000\n",
      "158/158 [==============================] - 0s 165us/step - loss: 0.6996 - val_loss: 1.2030\n",
      "Epoch 51/1000\n",
      "158/158 [==============================] - 0s 157us/step - loss: 0.6943 - val_loss: 1.1960\n",
      "Epoch 52/1000\n",
      "158/158 [==============================] - 0s 165us/step - loss: 0.6890 - val_loss: 1.1891\n",
      "Epoch 53/1000\n",
      "158/158 [==============================] - 0s 127us/step - loss: 0.6837 - val_loss: 1.1822\n",
      "Epoch 54/1000\n",
      "158/158 [==============================] - 0s 114us/step - loss: 0.6784 - val_loss: 1.1753\n",
      "Epoch 55/1000\n",
      "158/158 [==============================] - 0s 148us/step - loss: 0.6733 - val_loss: 1.1684\n",
      "Epoch 56/1000\n",
      "158/158 [==============================] - 0s 146us/step - loss: 0.6681 - val_loss: 1.1615\n",
      "Epoch 57/1000\n",
      "158/158 [==============================] - 0s 176us/step - loss: 0.6630 - val_loss: 1.1547\n",
      "Epoch 58/1000\n",
      "158/158 [==============================] - 0s 155us/step - loss: 0.6579 - val_loss: 1.1479\n",
      "Epoch 59/1000\n",
      "158/158 [==============================] - 0s 195us/step - loss: 0.6529 - val_loss: 1.1410\n",
      "Epoch 60/1000\n",
      "158/158 [==============================] - 0s 155us/step - loss: 0.6478 - val_loss: 1.1342\n",
      "Epoch 61/1000\n",
      "158/158 [==============================] - 0s 130us/step - loss: 0.6429 - val_loss: 1.1274\n",
      "Epoch 62/1000\n",
      "158/158 [==============================] - 0s 143us/step - loss: 0.6379 - val_loss: 1.1207\n",
      "Epoch 63/1000\n",
      "158/158 [==============================] - 0s 158us/step - loss: 0.6330 - val_loss: 1.1139\n",
      "Epoch 64/1000\n",
      "158/158 [==============================] - 0s 155us/step - loss: 0.6280 - val_loss: 1.1071\n",
      "Epoch 65/1000\n",
      "158/158 [==============================] - 0s 177us/step - loss: 0.6232 - val_loss: 1.1004\n",
      "Epoch 66/1000\n",
      "158/158 [==============================] - 0s 221us/step - loss: 0.6183 - val_loss: 1.0937\n",
      "Epoch 67/1000\n",
      "158/158 [==============================] - 0s 186us/step - loss: 0.6135 - val_loss: 1.0870\n",
      "Epoch 68/1000\n",
      "158/158 [==============================] - 0s 214us/step - loss: 0.6087 - val_loss: 1.0803\n",
      "Epoch 69/1000\n",
      "158/158 [==============================] - 0s 153us/step - loss: 0.6039 - val_loss: 1.0736\n",
      "Epoch 70/1000\n",
      "158/158 [==============================] - 0s 153us/step - loss: 0.5992 - val_loss: 1.0669\n",
      "Epoch 71/1000\n",
      "158/158 [==============================] - 0s 129us/step - loss: 0.5944 - val_loss: 1.0602\n",
      "Epoch 72/1000\n",
      "158/158 [==============================] - 0s 134us/step - loss: 0.5897 - val_loss: 1.0536\n",
      "Epoch 73/1000\n",
      "158/158 [==============================] - 0s 139us/step - loss: 0.5850 - val_loss: 1.0469\n",
      "Epoch 74/1000\n",
      "158/158 [==============================] - 0s 156us/step - loss: 0.5804 - val_loss: 1.0403\n",
      "Epoch 75/1000\n",
      "158/158 [==============================] - 0s 180us/step - loss: 0.5757 - val_loss: 1.0337\n",
      "Epoch 76/1000\n",
      "158/158 [==============================] - 0s 162us/step - loss: 0.5711 - val_loss: 1.0271\n",
      "Epoch 77/1000\n",
      "158/158 [==============================] - 0s 139us/step - loss: 0.5665 - val_loss: 1.0205\n",
      "Epoch 78/1000\n",
      "158/158 [==============================] - 0s 173us/step - loss: 0.5619 - val_loss: 1.0138\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 79/1000\n",
      "158/158 [==============================] - 0s 133us/step - loss: 0.5573 - val_loss: 1.0072\n",
      "Epoch 80/1000\n",
      "158/158 [==============================] - 0s 143us/step - loss: 0.5527 - val_loss: 1.0006\n",
      "Epoch 81/1000\n",
      "158/158 [==============================] - 0s 153us/step - loss: 0.5482 - val_loss: 0.9940\n",
      "Epoch 82/1000\n",
      "158/158 [==============================] - 0s 142us/step - loss: 0.5437 - val_loss: 0.9874\n",
      "Epoch 83/1000\n",
      "158/158 [==============================] - 0s 169us/step - loss: 0.5392 - val_loss: 0.9809\n",
      "Epoch 84/1000\n",
      "158/158 [==============================] - 0s 208us/step - loss: 0.5347 - val_loss: 0.9742\n",
      "Epoch 85/1000\n",
      "158/158 [==============================] - 0s 164us/step - loss: 0.5302 - val_loss: 0.9677\n",
      "Epoch 86/1000\n",
      "158/158 [==============================] - 0s 142us/step - loss: 0.5258 - val_loss: 0.9611\n",
      "Epoch 87/1000\n",
      "158/158 [==============================] - 0s 135us/step - loss: 0.5214 - val_loss: 0.9545\n",
      "Epoch 88/1000\n",
      "158/158 [==============================] - 0s 144us/step - loss: 0.5170 - val_loss: 0.9479\n",
      "Epoch 89/1000\n",
      "158/158 [==============================] - 0s 134us/step - loss: 0.5126 - val_loss: 0.9414\n",
      "Epoch 90/1000\n",
      "158/158 [==============================] - 0s 146us/step - loss: 0.5082 - val_loss: 0.9348\n",
      "Epoch 91/1000\n",
      "158/158 [==============================] - 0s 125us/step - loss: 0.5039 - val_loss: 0.9282\n",
      "Epoch 92/1000\n",
      "158/158 [==============================] - 0s 133us/step - loss: 0.4995 - val_loss: 0.9216\n",
      "Epoch 93/1000\n",
      "158/158 [==============================] - 0s 148us/step - loss: 0.4952 - val_loss: 0.9150\n",
      "Epoch 94/1000\n",
      "158/158 [==============================] - 0s 166us/step - loss: 0.4909 - val_loss: 0.9084\n",
      "Epoch 95/1000\n",
      "158/158 [==============================] - 0s 169us/step - loss: 0.4867 - val_loss: 0.9018\n",
      "Epoch 96/1000\n",
      "158/158 [==============================] - 0s 157us/step - loss: 0.4824 - val_loss: 0.8951\n",
      "Epoch 97/1000\n",
      "158/158 [==============================] - 0s 138us/step - loss: 0.4782 - val_loss: 0.8885\n",
      "Epoch 98/1000\n",
      "158/158 [==============================] - 0s 125us/step - loss: 0.4740 - val_loss: 0.8818\n",
      "Epoch 99/1000\n",
      "158/158 [==============================] - 0s 143us/step - loss: 0.4698 - val_loss: 0.8752\n",
      "Epoch 100/1000\n",
      "158/158 [==============================] - 0s 133us/step - loss: 0.4656 - val_loss: 0.8685\n",
      "Epoch 101/1000\n",
      "158/158 [==============================] - 0s 147us/step - loss: 0.4615 - val_loss: 0.8618\n",
      "Epoch 102/1000\n",
      "158/158 [==============================] - 0s 139us/step - loss: 0.4574 - val_loss: 0.8551\n",
      "Epoch 103/1000\n",
      "158/158 [==============================] - 0s 138us/step - loss: 0.4533 - val_loss: 0.8484\n",
      "Epoch 104/1000\n",
      "158/158 [==============================] - 0s 149us/step - loss: 0.4493 - val_loss: 0.8417\n",
      "Epoch 105/1000\n",
      "158/158 [==============================] - 0s 157us/step - loss: 0.4453 - val_loss: 0.8350\n",
      "Epoch 106/1000\n",
      "158/158 [==============================] - 0s 185us/step - loss: 0.4413 - val_loss: 0.8282\n",
      "Epoch 107/1000\n",
      "158/158 [==============================] - 0s 189us/step - loss: 0.4373 - val_loss: 0.8215\n",
      "Epoch 108/1000\n",
      "158/158 [==============================] - 0s 149us/step - loss: 0.4333 - val_loss: 0.8147\n",
      "Epoch 109/1000\n",
      "158/158 [==============================] - 0s 140us/step - loss: 0.4294 - val_loss: 0.8079\n",
      "Epoch 110/1000\n",
      "158/158 [==============================] - 0s 320us/step - loss: 0.4255 - val_loss: 0.8011\n",
      "Epoch 111/1000\n",
      "158/158 [==============================] - 0s 161us/step - loss: 0.4216 - val_loss: 0.7943\n",
      "Epoch 112/1000\n",
      "158/158 [==============================] - 0s 148us/step - loss: 0.4178 - val_loss: 0.7874\n",
      "Epoch 113/1000\n",
      "158/158 [==============================] - 0s 134us/step - loss: 0.4140 - val_loss: 0.7806\n",
      "Epoch 114/1000\n",
      "158/158 [==============================] - 0s 174us/step - loss: 0.4102 - val_loss: 0.7737\n",
      "Epoch 115/1000\n",
      "158/158 [==============================] - 0s 213us/step - loss: 0.4064 - val_loss: 0.7668\n",
      "Epoch 116/1000\n",
      "158/158 [==============================] - 0s 182us/step - loss: 0.4027 - val_loss: 0.7598\n",
      "Epoch 117/1000\n",
      "158/158 [==============================] - 0s 186us/step - loss: 0.3989 - val_loss: 0.7529\n",
      "Epoch 118/1000\n",
      "158/158 [==============================] - 0s 169us/step - loss: 0.3953 - val_loss: 0.7459\n",
      "Epoch 119/1000\n",
      "158/158 [==============================] - 0s 108us/step - loss: 0.3916 - val_loss: 0.7390\n",
      "Epoch 120/1000\n",
      "158/158 [==============================] - 0s 117us/step - loss: 0.3879 - val_loss: 0.7320\n",
      "Epoch 121/1000\n",
      "158/158 [==============================] - 0s 143us/step - loss: 0.3843 - val_loss: 0.7249\n",
      "Epoch 122/1000\n",
      "158/158 [==============================] - 0s 179us/step - loss: 0.3807 - val_loss: 0.7179\n",
      "Epoch 123/1000\n",
      "158/158 [==============================] - 0s 174us/step - loss: 0.3771 - val_loss: 0.7108\n",
      "Epoch 124/1000\n",
      "158/158 [==============================] - 0s 122us/step - loss: 0.3736 - val_loss: 0.7038\n",
      "Epoch 125/1000\n",
      "158/158 [==============================] - 0s 133us/step - loss: 0.3701 - val_loss: 0.6967\n",
      "Epoch 126/1000\n",
      "158/158 [==============================] - 0s 183us/step - loss: 0.3666 - val_loss: 0.6896\n",
      "Epoch 127/1000\n",
      "158/158 [==============================] - 0s 187us/step - loss: 0.3631 - val_loss: 0.6825\n",
      "Epoch 128/1000\n",
      "158/158 [==============================] - 0s 146us/step - loss: 0.3596 - val_loss: 0.6754\n",
      "Epoch 129/1000\n",
      "158/158 [==============================] - 0s 185us/step - loss: 0.3562 - val_loss: 0.6683\n",
      "Epoch 130/1000\n",
      "158/158 [==============================] - 0s 165us/step - loss: 0.3527 - val_loss: 0.6611\n",
      "Epoch 131/1000\n",
      "158/158 [==============================] - 0s 154us/step - loss: 0.3493 - val_loss: 0.6540\n",
      "Epoch 132/1000\n",
      "158/158 [==============================] - 0s 165us/step - loss: 0.3460 - val_loss: 0.6468\n",
      "Epoch 133/1000\n",
      "158/158 [==============================] - 0s 180us/step - loss: 0.3426 - val_loss: 0.6396\n",
      "Epoch 134/1000\n",
      "158/158 [==============================] - 0s 146us/step - loss: 0.3392 - val_loss: 0.6325\n",
      "Epoch 135/1000\n",
      "158/158 [==============================] - 0s 154us/step - loss: 0.3359 - val_loss: 0.6253\n",
      "Epoch 136/1000\n",
      "158/158 [==============================] - 0s 152us/step - loss: 0.3326 - val_loss: 0.6181\n",
      "Epoch 137/1000\n",
      "158/158 [==============================] - 0s 172us/step - loss: 0.3293 - val_loss: 0.6109\n",
      "Epoch 138/1000\n",
      "158/158 [==============================] - 0s 169us/step - loss: 0.3260 - val_loss: 0.6038\n",
      "Epoch 139/1000\n",
      "158/158 [==============================] - 0s 164us/step - loss: 0.3228 - val_loss: 0.5966\n",
      "Epoch 140/1000\n",
      "158/158 [==============================] - 0s 162us/step - loss: 0.3195 - val_loss: 0.5894\n",
      "Epoch 141/1000\n",
      "158/158 [==============================] - 0s 148us/step - loss: 0.3163 - val_loss: 0.5823\n",
      "Epoch 142/1000\n",
      "158/158 [==============================] - 0s 190us/step - loss: 0.3131 - val_loss: 0.5751\n",
      "Epoch 143/1000\n",
      "158/158 [==============================] - 0s 149us/step - loss: 0.3099 - val_loss: 0.5680\n",
      "Epoch 144/1000\n",
      "158/158 [==============================] - 0s 152us/step - loss: 0.3067 - val_loss: 0.5609\n",
      "Epoch 145/1000\n",
      "158/158 [==============================] - 0s 123us/step - loss: 0.3035 - val_loss: 0.5537\n",
      "Epoch 146/1000\n",
      "158/158 [==============================] - 0s 164us/step - loss: 0.3004 - val_loss: 0.5466\n",
      "Epoch 147/1000\n",
      "158/158 [==============================] - 0s 170us/step - loss: 0.2973 - val_loss: 0.5396\n",
      "Epoch 148/1000\n",
      "158/158 [==============================] - 0s 131us/step - loss: 0.2941 - val_loss: 0.5325\n",
      "Epoch 149/1000\n",
      "158/158 [==============================] - 0s 124us/step - loss: 0.2910 - val_loss: 0.5255\n",
      "Epoch 150/1000\n",
      "158/158 [==============================] - 0s 155us/step - loss: 0.2880 - val_loss: 0.5185\n",
      "Epoch 151/1000\n",
      "158/158 [==============================] - 0s 144us/step - loss: 0.2849 - val_loss: 0.5115\n",
      "Epoch 152/1000\n",
      "158/158 [==============================] - 0s 159us/step - loss: 0.2819 - val_loss: 0.5046\n",
      "Epoch 153/1000\n",
      "158/158 [==============================] - 0s 164us/step - loss: 0.2788 - val_loss: 0.4977\n",
      "Epoch 154/1000\n",
      "158/158 [==============================] - 0s 130us/step - loss: 0.2758 - val_loss: 0.4908\n",
      "Epoch 155/1000\n",
      "158/158 [==============================] - 0s 154us/step - loss: 0.2728 - val_loss: 0.4839\n",
      "Epoch 156/1000\n",
      "158/158 [==============================] - 0s 164us/step - loss: 0.2698 - val_loss: 0.4771\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 157/1000\n",
      "158/158 [==============================] - 0s 126us/step - loss: 0.2669 - val_loss: 0.4704\n",
      "Epoch 158/1000\n",
      "158/158 [==============================] - 0s 147us/step - loss: 0.2639 - val_loss: 0.4637\n",
      "Epoch 159/1000\n",
      "158/158 [==============================] - 0s 147us/step - loss: 0.2610 - val_loss: 0.4570\n",
      "Epoch 160/1000\n",
      "158/158 [==============================] - 0s 212us/step - loss: 0.2581 - val_loss: 0.4504\n",
      "Epoch 161/1000\n",
      "158/158 [==============================] - 0s 187us/step - loss: 0.2552 - val_loss: 0.4438\n",
      "Epoch 162/1000\n",
      "158/158 [==============================] - 0s 140us/step - loss: 0.2523 - val_loss: 0.4372\n",
      "Epoch 163/1000\n",
      "158/158 [==============================] - 0s 153us/step - loss: 0.2495 - val_loss: 0.4308\n",
      "Epoch 164/1000\n",
      "158/158 [==============================] - 0s 137us/step - loss: 0.2467 - val_loss: 0.4244\n",
      "Epoch 165/1000\n",
      "158/158 [==============================] - 0s 146us/step - loss: 0.2439 - val_loss: 0.4180\n",
      "Epoch 166/1000\n",
      "158/158 [==============================] - 0s 149us/step - loss: 0.2411 - val_loss: 0.4117\n",
      "Epoch 167/1000\n",
      "158/158 [==============================] - 0s 148us/step - loss: 0.2383 - val_loss: 0.4055\n",
      "Epoch 168/1000\n",
      "158/158 [==============================] - 0s 139us/step - loss: 0.2356 - val_loss: 0.3993\n",
      "Epoch 169/1000\n",
      "158/158 [==============================] - 0s 146us/step - loss: 0.2329 - val_loss: 0.3932\n",
      "Epoch 170/1000\n",
      "158/158 [==============================] - 0s 134us/step - loss: 0.2302 - val_loss: 0.3872\n",
      "Epoch 171/1000\n",
      "158/158 [==============================] - 0s 154us/step - loss: 0.2275 - val_loss: 0.3812\n",
      "Epoch 172/1000\n",
      "158/158 [==============================] - 0s 165us/step - loss: 0.2249 - val_loss: 0.3753\n",
      "Epoch 173/1000\n",
      "158/158 [==============================] - 0s 190us/step - loss: 0.2222 - val_loss: 0.3695\n",
      "Epoch 174/1000\n",
      "158/158 [==============================] - 0s 159us/step - loss: 0.2196 - val_loss: 0.3637\n",
      "Epoch 175/1000\n",
      "158/158 [==============================] - 0s 123us/step - loss: 0.2171 - val_loss: 0.3580\n",
      "Epoch 176/1000\n",
      "158/158 [==============================] - 0s 131us/step - loss: 0.2145 - val_loss: 0.3524\n",
      "Epoch 177/1000\n",
      "158/158 [==============================] - 0s 145us/step - loss: 0.2120 - val_loss: 0.3468\n",
      "Epoch 178/1000\n",
      "158/158 [==============================] - 0s 117us/step - loss: 0.2095 - val_loss: 0.3414\n",
      "Epoch 179/1000\n",
      "158/158 [==============================] - 0s 132us/step - loss: 0.2070 - val_loss: 0.3360\n",
      "Epoch 180/1000\n",
      "158/158 [==============================] - 0s 113us/step - loss: 0.2046 - val_loss: 0.3306\n",
      "Epoch 181/1000\n",
      "158/158 [==============================] - 0s 124us/step - loss: 0.2022 - val_loss: 0.3254\n",
      "Epoch 182/1000\n",
      "158/158 [==============================] - 0s 106us/step - loss: 0.1998 - val_loss: 0.3202\n",
      "Epoch 183/1000\n",
      "158/158 [==============================] - 0s 110us/step - loss: 0.1974 - val_loss: 0.3151\n",
      "Epoch 184/1000\n",
      "158/158 [==============================] - 0s 145us/step - loss: 0.1951 - val_loss: 0.3101\n",
      "Epoch 185/1000\n",
      "158/158 [==============================] - 0s 150us/step - loss: 0.1928 - val_loss: 0.3051\n",
      "Epoch 186/1000\n",
      "158/158 [==============================] - 0s 159us/step - loss: 0.1905 - val_loss: 0.3003\n",
      "Epoch 187/1000\n",
      "158/158 [==============================] - 0s 183us/step - loss: 0.1882 - val_loss: 0.2955\n",
      "Epoch 188/1000\n",
      "158/158 [==============================] - 0s 153us/step - loss: 0.1860 - val_loss: 0.2908\n",
      "Epoch 189/1000\n",
      "158/158 [==============================] - 0s 186us/step - loss: 0.1838 - val_loss: 0.2861\n",
      "Epoch 190/1000\n",
      "158/158 [==============================] - 0s 162us/step - loss: 0.1816 - val_loss: 0.2816\n",
      "Epoch 191/1000\n",
      "158/158 [==============================] - 0s 162us/step - loss: 0.1795 - val_loss: 0.2771\n",
      "Epoch 192/1000\n",
      "158/158 [==============================] - 0s 149us/step - loss: 0.1773 - val_loss: 0.2727\n",
      "Epoch 193/1000\n",
      "158/158 [==============================] - 0s 180us/step - loss: 0.1753 - val_loss: 0.2683\n",
      "Epoch 194/1000\n",
      "158/158 [==============================] - 0s 182us/step - loss: 0.1732 - val_loss: 0.2641\n",
      "Epoch 195/1000\n",
      "158/158 [==============================] - 0s 134us/step - loss: 0.1712 - val_loss: 0.2599\n",
      "Epoch 196/1000\n",
      "158/158 [==============================] - 0s 144us/step - loss: 0.1691 - val_loss: 0.2558\n",
      "Epoch 197/1000\n",
      "158/158 [==============================] - 0s 180us/step - loss: 0.1672 - val_loss: 0.2517\n",
      "Epoch 198/1000\n",
      "158/158 [==============================] - 0s 189us/step - loss: 0.1652 - val_loss: 0.2478\n",
      "Epoch 199/1000\n",
      "158/158 [==============================] - 0s 185us/step - loss: 0.1633 - val_loss: 0.2439\n",
      "Epoch 200/1000\n",
      "158/158 [==============================] - 0s 174us/step - loss: 0.1614 - val_loss: 0.2401\n",
      "Epoch 201/1000\n",
      "158/158 [==============================] - 0s 147us/step - loss: 0.1595 - val_loss: 0.2363\n",
      "Epoch 202/1000\n",
      "158/158 [==============================] - 0s 131us/step - loss: 0.1577 - val_loss: 0.2327\n",
      "Epoch 203/1000\n",
      "158/158 [==============================] - 0s 175us/step - loss: 0.1559 - val_loss: 0.2291\n",
      "Epoch 204/1000\n",
      "158/158 [==============================] - 0s 199us/step - loss: 0.1541 - val_loss: 0.2255\n",
      "Epoch 205/1000\n",
      "158/158 [==============================] - 0s 145us/step - loss: 0.1523 - val_loss: 0.2221\n",
      "Epoch 206/1000\n",
      "158/158 [==============================] - 0s 211us/step - loss: 0.1506 - val_loss: 0.2187\n",
      "Epoch 207/1000\n",
      "158/158 [==============================] - 0s 166us/step - loss: 0.1489 - val_loss: 0.2154\n",
      "Epoch 208/1000\n",
      "158/158 [==============================] - 0s 162us/step - loss: 0.1472 - val_loss: 0.2121\n",
      "Epoch 209/1000\n",
      "158/158 [==============================] - 0s 170us/step - loss: 0.1455 - val_loss: 0.2089\n",
      "Epoch 210/1000\n",
      "158/158 [==============================] - 0s 129us/step - loss: 0.1439 - val_loss: 0.2058\n",
      "Epoch 211/1000\n",
      "158/158 [==============================] - 0s 144us/step - loss: 0.1423 - val_loss: 0.2027\n",
      "Epoch 212/1000\n",
      "158/158 [==============================] - 0s 122us/step - loss: 0.1407 - val_loss: 0.1997\n",
      "Epoch 213/1000\n",
      "158/158 [==============================] - 0s 163us/step - loss: 0.1392 - val_loss: 0.1968\n",
      "Epoch 214/1000\n",
      "158/158 [==============================] - 0s 182us/step - loss: 0.1376 - val_loss: 0.1939\n",
      "Epoch 215/1000\n",
      "158/158 [==============================] - 0s 174us/step - loss: 0.1361 - val_loss: 0.1911\n",
      "Epoch 216/1000\n",
      "158/158 [==============================] - 0s 132us/step - loss: 0.1346 - val_loss: 0.1884\n",
      "Epoch 217/1000\n",
      "158/158 [==============================] - 0s 135us/step - loss: 0.1332 - val_loss: 0.1857\n",
      "Epoch 218/1000\n",
      "158/158 [==============================] - 0s 123us/step - loss: 0.1317 - val_loss: 0.1831\n",
      "Epoch 219/1000\n",
      "158/158 [==============================] - 0s 175us/step - loss: 0.1303 - val_loss: 0.1806\n",
      "Epoch 220/1000\n",
      "158/158 [==============================] - 0s 142us/step - loss: 0.1289 - val_loss: 0.1781\n",
      "Epoch 221/1000\n",
      "158/158 [==============================] - 0s 175us/step - loss: 0.1275 - val_loss: 0.1756\n",
      "Epoch 222/1000\n",
      "158/158 [==============================] - 0s 150us/step - loss: 0.1262 - val_loss: 0.1732\n",
      "Epoch 223/1000\n",
      "158/158 [==============================] - 0s 148us/step - loss: 0.1249 - val_loss: 0.1709\n",
      "Epoch 224/1000\n",
      "158/158 [==============================] - 0s 178us/step - loss: 0.1236 - val_loss: 0.1686\n",
      "Epoch 225/1000\n",
      "158/158 [==============================] - 0s 143us/step - loss: 0.1223 - val_loss: 0.1664\n",
      "Epoch 226/1000\n",
      "158/158 [==============================] - 0s 141us/step - loss: 0.1210 - val_loss: 0.1643\n",
      "Epoch 227/1000\n",
      "158/158 [==============================] - 0s 135us/step - loss: 0.1198 - val_loss: 0.1622\n",
      "Epoch 228/1000\n",
      "158/158 [==============================] - 0s 151us/step - loss: 0.1185 - val_loss: 0.1601\n",
      "Epoch 229/1000\n",
      "158/158 [==============================] - 0s 146us/step - loss: 0.1173 - val_loss: 0.1581\n",
      "Epoch 230/1000\n",
      "158/158 [==============================] - 0s 119us/step - loss: 0.1161 - val_loss: 0.1562\n",
      "Epoch 231/1000\n",
      "158/158 [==============================] - 0s 169us/step - loss: 0.1150 - val_loss: 0.1543\n",
      "Epoch 232/1000\n",
      "158/158 [==============================] - 0s 161us/step - loss: 0.1138 - val_loss: 0.1524\n",
      "Epoch 233/1000\n",
      "158/158 [==============================] - 0s 130us/step - loss: 0.1127 - val_loss: 0.1506\n",
      "Epoch 234/1000\n",
      "158/158 [==============================] - 0s 175us/step - loss: 0.1116 - val_loss: 0.1489\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 235/1000\n",
      "158/158 [==============================] - 0s 185us/step - loss: 0.1104 - val_loss: 0.1471\n",
      "Epoch 236/1000\n",
      "158/158 [==============================] - 0s 133us/step - loss: 0.1094 - val_loss: 0.1455\n",
      "Epoch 237/1000\n",
      "158/158 [==============================] - 0s 144us/step - loss: 0.1083 - val_loss: 0.1439\n",
      "Epoch 238/1000\n",
      "158/158 [==============================] - 0s 141us/step - loss: 0.1072 - val_loss: 0.1423\n",
      "Epoch 239/1000\n",
      "158/158 [==============================] - 0s 160us/step - loss: 0.1062 - val_loss: 0.1408\n",
      "Epoch 240/1000\n",
      "158/158 [==============================] - 0s 142us/step - loss: 0.1052 - val_loss: 0.1393\n",
      "Epoch 241/1000\n",
      "158/158 [==============================] - 0s 139us/step - loss: 0.1042 - val_loss: 0.1378\n",
      "Epoch 242/1000\n",
      "158/158 [==============================] - 0s 133us/step - loss: 0.1032 - val_loss: 0.1364\n",
      "Epoch 243/1000\n",
      "158/158 [==============================] - 0s 127us/step - loss: 0.1022 - val_loss: 0.1350\n",
      "Epoch 244/1000\n",
      "158/158 [==============================] - 0s 135us/step - loss: 0.1012 - val_loss: 0.1337\n",
      "Epoch 245/1000\n",
      "158/158 [==============================] - 0s 148us/step - loss: 0.1003 - val_loss: 0.1324\n",
      "Epoch 246/1000\n",
      "158/158 [==============================] - 0s 192us/step - loss: 0.0993 - val_loss: 0.1311\n",
      "Epoch 247/1000\n",
      "158/158 [==============================] - 0s 171us/step - loss: 0.0984 - val_loss: 0.1299\n",
      "Epoch 248/1000\n",
      "158/158 [==============================] - 0s 152us/step - loss: 0.0975 - val_loss: 0.1287\n",
      "Epoch 249/1000\n",
      "158/158 [==============================] - 0s 137us/step - loss: 0.0966 - val_loss: 0.1275\n",
      "Epoch 250/1000\n",
      "158/158 [==============================] - 0s 159us/step - loss: 0.0957 - val_loss: 0.1264\n",
      "Epoch 251/1000\n",
      "158/158 [==============================] - 0s 145us/step - loss: 0.0948 - val_loss: 0.1253\n",
      "Epoch 252/1000\n",
      "158/158 [==============================] - 0s 158us/step - loss: 0.0939 - val_loss: 0.1242\n",
      "Epoch 253/1000\n",
      "158/158 [==============================] - 0s 163us/step - loss: 0.0930 - val_loss: 0.1232\n",
      "Epoch 254/1000\n",
      "158/158 [==============================] - 0s 158us/step - loss: 0.0922 - val_loss: 0.1221\n",
      "Epoch 255/1000\n",
      "158/158 [==============================] - 0s 142us/step - loss: 0.0913 - val_loss: 0.1211\n",
      "Epoch 256/1000\n",
      "158/158 [==============================] - 0s 138us/step - loss: 0.0905 - val_loss: 0.1202\n",
      "Epoch 257/1000\n",
      "158/158 [==============================] - 0s 157us/step - loss: 0.0897 - val_loss: 0.1192\n",
      "Epoch 258/1000\n",
      "158/158 [==============================] - 0s 168us/step - loss: 0.0889 - val_loss: 0.1183\n",
      "Epoch 259/1000\n",
      "158/158 [==============================] - 0s 134us/step - loss: 0.0881 - val_loss: 0.1174\n",
      "Epoch 260/1000\n",
      "158/158 [==============================] - 0s 175us/step - loss: 0.0873 - val_loss: 0.1165\n",
      "Epoch 261/1000\n",
      "158/158 [==============================] - 0s 150us/step - loss: 0.0865 - val_loss: 0.1157\n",
      "Epoch 262/1000\n",
      "158/158 [==============================] - 0s 183us/step - loss: 0.0857 - val_loss: 0.1148\n",
      "Epoch 263/1000\n",
      "158/158 [==============================] - 0s 136us/step - loss: 0.0850 - val_loss: 0.1140\n",
      "Epoch 264/1000\n",
      "158/158 [==============================] - 0s 151us/step - loss: 0.0842 - val_loss: 0.1132\n",
      "Epoch 265/1000\n",
      "158/158 [==============================] - 0s 146us/step - loss: 0.0834 - val_loss: 0.1124\n",
      "Epoch 266/1000\n",
      "158/158 [==============================] - 0s 120us/step - loss: 0.0827 - val_loss: 0.1117\n",
      "Epoch 267/1000\n",
      "158/158 [==============================] - 0s 157us/step - loss: 0.0820 - val_loss: 0.1109\n",
      "Epoch 268/1000\n",
      "158/158 [==============================] - 0s 155us/step - loss: 0.0812 - val_loss: 0.1102\n",
      "Epoch 269/1000\n",
      "158/158 [==============================] - 0s 140us/step - loss: 0.0805 - val_loss: 0.1094\n",
      "Epoch 270/1000\n",
      "158/158 [==============================] - 0s 187us/step - loss: 0.0798 - val_loss: 0.1087\n",
      "Epoch 271/1000\n",
      "158/158 [==============================] - 0s 159us/step - loss: 0.0791 - val_loss: 0.1080\n",
      "Epoch 272/1000\n",
      "158/158 [==============================] - 0s 134us/step - loss: 0.0784 - val_loss: 0.1073\n",
      "Epoch 273/1000\n",
      "158/158 [==============================] - 0s 142us/step - loss: 0.0777 - val_loss: 0.1067\n",
      "Epoch 274/1000\n",
      "158/158 [==============================] - 0s 149us/step - loss: 0.0770 - val_loss: 0.1060\n",
      "Epoch 275/1000\n",
      "158/158 [==============================] - 0s 144us/step - loss: 0.0764 - val_loss: 0.1054\n",
      "Epoch 276/1000\n",
      "158/158 [==============================] - 0s 149us/step - loss: 0.0757 - val_loss: 0.1047\n",
      "Epoch 277/1000\n",
      "158/158 [==============================] - 0s 143us/step - loss: 0.0751 - val_loss: 0.1041\n",
      "Epoch 278/1000\n",
      "158/158 [==============================] - 0s 139us/step - loss: 0.0744 - val_loss: 0.1035\n",
      "Epoch 279/1000\n",
      "158/158 [==============================] - 0s 161us/step - loss: 0.0738 - val_loss: 0.1029\n",
      "Epoch 280/1000\n",
      "158/158 [==============================] - 0s 175us/step - loss: 0.0731 - val_loss: 0.1023\n",
      "Epoch 281/1000\n",
      "158/158 [==============================] - 0s 172us/step - loss: 0.0725 - val_loss: 0.1017\n",
      "Epoch 282/1000\n",
      "158/158 [==============================] - 0s 120us/step - loss: 0.0719 - val_loss: 0.1011\n",
      "Epoch 283/1000\n",
      "158/158 [==============================] - 0s 151us/step - loss: 0.0713 - val_loss: 0.1005\n",
      "Epoch 284/1000\n",
      "158/158 [==============================] - 0s 121us/step - loss: 0.0707 - val_loss: 0.0999\n",
      "Epoch 285/1000\n",
      "158/158 [==============================] - 0s 133us/step - loss: 0.0701 - val_loss: 0.0994\n",
      "Epoch 286/1000\n",
      "158/158 [==============================] - 0s 124us/step - loss: 0.0695 - val_loss: 0.0988\n",
      "Epoch 287/1000\n",
      "158/158 [==============================] - 0s 140us/step - loss: 0.0689 - val_loss: 0.0982\n",
      "Epoch 288/1000\n",
      "158/158 [==============================] - 0s 167us/step - loss: 0.0683 - val_loss: 0.0977\n",
      "Epoch 289/1000\n",
      "158/158 [==============================] - 0s 209us/step - loss: 0.0678 - val_loss: 0.0972\n",
      "Epoch 290/1000\n",
      "158/158 [==============================] - 0s 146us/step - loss: 0.0672 - val_loss: 0.0966\n",
      "Epoch 291/1000\n",
      "158/158 [==============================] - 0s 159us/step - loss: 0.0666 - val_loss: 0.0961\n",
      "Epoch 292/1000\n",
      "158/158 [==============================] - 0s 169us/step - loss: 0.0661 - val_loss: 0.0956\n",
      "Epoch 293/1000\n",
      "158/158 [==============================] - 0s 176us/step - loss: 0.0656 - val_loss: 0.0950\n",
      "Epoch 294/1000\n",
      "158/158 [==============================] - 0s 164us/step - loss: 0.0650 - val_loss: 0.0945\n",
      "Epoch 295/1000\n",
      "158/158 [==============================] - 0s 167us/step - loss: 0.0645 - val_loss: 0.0940\n",
      "Epoch 296/1000\n",
      "158/158 [==============================] - 0s 137us/step - loss: 0.0640 - val_loss: 0.0935\n",
      "Epoch 297/1000\n",
      "158/158 [==============================] - 0s 145us/step - loss: 0.0635 - val_loss: 0.0930\n",
      "Epoch 298/1000\n",
      "158/158 [==============================] - 0s 163us/step - loss: 0.0630 - val_loss: 0.0925\n",
      "Epoch 299/1000\n",
      "158/158 [==============================] - 0s 154us/step - loss: 0.0625 - val_loss: 0.0920\n",
      "Epoch 300/1000\n",
      "158/158 [==============================] - 0s 159us/step - loss: 0.0620 - val_loss: 0.0915\n",
      "Epoch 301/1000\n",
      "158/158 [==============================] - 0s 118us/step - loss: 0.0615 - val_loss: 0.0910\n",
      "Epoch 302/1000\n",
      "158/158 [==============================] - 0s 125us/step - loss: 0.0610 - val_loss: 0.0905\n",
      "Epoch 303/1000\n",
      "158/158 [==============================] - 0s 128us/step - loss: 0.0606 - val_loss: 0.0900\n",
      "Epoch 304/1000\n",
      "158/158 [==============================] - 0s 138us/step - loss: 0.0601 - val_loss: 0.0896\n",
      "Epoch 305/1000\n",
      "158/158 [==============================] - 0s 157us/step - loss: 0.0596 - val_loss: 0.0891\n",
      "Epoch 306/1000\n",
      "158/158 [==============================] - 0s 150us/step - loss: 0.0592 - val_loss: 0.0886\n",
      "Epoch 307/1000\n",
      "158/158 [==============================] - 0s 140us/step - loss: 0.0587 - val_loss: 0.0881\n",
      "Epoch 308/1000\n",
      "158/158 [==============================] - 0s 166us/step - loss: 0.0583 - val_loss: 0.0877\n",
      "Epoch 309/1000\n",
      "158/158 [==============================] - 0s 150us/step - loss: 0.0579 - val_loss: 0.0872\n",
      "Epoch 310/1000\n",
      "158/158 [==============================] - 0s 149us/step - loss: 0.0574 - val_loss: 0.0867\n",
      "Epoch 311/1000\n",
      "158/158 [==============================] - 0s 123us/step - loss: 0.0570 - val_loss: 0.0863\n",
      "Epoch 312/1000\n",
      "158/158 [==============================] - 0s 142us/step - loss: 0.0566 - val_loss: 0.0858\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 313/1000\n",
      "158/158 [==============================] - 0s 180us/step - loss: 0.0562 - val_loss: 0.0854\n",
      "Epoch 314/1000\n",
      "158/158 [==============================] - 0s 156us/step - loss: 0.0558 - val_loss: 0.0849\n",
      "Epoch 315/1000\n",
      "158/158 [==============================] - 0s 132us/step - loss: 0.0554 - val_loss: 0.0845\n",
      "Epoch 316/1000\n",
      "158/158 [==============================] - 0s 156us/step - loss: 0.0550 - val_loss: 0.0840\n",
      "Epoch 317/1000\n",
      "158/158 [==============================] - 0s 178us/step - loss: 0.0547 - val_loss: 0.0836\n",
      "Epoch 318/1000\n",
      "158/158 [==============================] - 0s 154us/step - loss: 0.0543 - val_loss: 0.0832\n",
      "Epoch 319/1000\n",
      "158/158 [==============================] - 0s 251us/step - loss: 0.0539 - val_loss: 0.0827\n",
      "Epoch 320/1000\n",
      "158/158 [==============================] - 0s 166us/step - loss: 0.0536 - val_loss: 0.0823\n",
      "Epoch 321/1000\n",
      "158/158 [==============================] - 0s 144us/step - loss: 0.0532 - val_loss: 0.0819\n",
      "Epoch 322/1000\n",
      "158/158 [==============================] - 0s 160us/step - loss: 0.0529 - val_loss: 0.0815\n",
      "Epoch 323/1000\n",
      "158/158 [==============================] - 0s 144us/step - loss: 0.0525 - val_loss: 0.0810\n",
      "Epoch 324/1000\n",
      "158/158 [==============================] - 0s 167us/step - loss: 0.0522 - val_loss: 0.0806\n",
      "Epoch 325/1000\n",
      "158/158 [==============================] - 0s 201us/step - loss: 0.0519 - val_loss: 0.0802\n",
      "Epoch 326/1000\n",
      "158/158 [==============================] - 0s 169us/step - loss: 0.0515 - val_loss: 0.0798\n",
      "Epoch 327/1000\n",
      "158/158 [==============================] - 0s 158us/step - loss: 0.0512 - val_loss: 0.0794\n",
      "Epoch 328/1000\n",
      "158/158 [==============================] - 0s 132us/step - loss: 0.0509 - val_loss: 0.0790\n",
      "Epoch 329/1000\n",
      "158/158 [==============================] - 0s 178us/step - loss: 0.0506 - val_loss: 0.0786\n",
      "Epoch 330/1000\n",
      "158/158 [==============================] - 0s 178us/step - loss: 0.0503 - val_loss: 0.0782\n",
      "Epoch 331/1000\n",
      "158/158 [==============================] - 0s 143us/step - loss: 0.0500 - val_loss: 0.0778\n",
      "Epoch 332/1000\n",
      "158/158 [==============================] - 0s 143us/step - loss: 0.0497 - val_loss: 0.0774\n",
      "Epoch 333/1000\n",
      "158/158 [==============================] - 0s 147us/step - loss: 0.0494 - val_loss: 0.0770\n",
      "Epoch 334/1000\n",
      "158/158 [==============================] - 0s 144us/step - loss: 0.0491 - val_loss: 0.0767\n",
      "Epoch 335/1000\n",
      "158/158 [==============================] - 0s 130us/step - loss: 0.0488 - val_loss: 0.0763\n",
      "Epoch 336/1000\n",
      "158/158 [==============================] - 0s 152us/step - loss: 0.0486 - val_loss: 0.0759\n",
      "Epoch 337/1000\n",
      "158/158 [==============================] - 0s 139us/step - loss: 0.0483 - val_loss: 0.0755\n",
      "Epoch 338/1000\n",
      "158/158 [==============================] - 0s 174us/step - loss: 0.0480 - val_loss: 0.0752\n",
      "Epoch 339/1000\n",
      "158/158 [==============================] - 0s 167us/step - loss: 0.0478 - val_loss: 0.0748\n",
      "Epoch 340/1000\n",
      "158/158 [==============================] - 0s 146us/step - loss: 0.0475 - val_loss: 0.0744\n",
      "Epoch 341/1000\n",
      "158/158 [==============================] - 0s 166us/step - loss: 0.0473 - val_loss: 0.0741\n",
      "Epoch 342/1000\n",
      "158/158 [==============================] - 0s 121us/step - loss: 0.0470 - val_loss: 0.0737\n",
      "Epoch 343/1000\n",
      "158/158 [==============================] - 0s 135us/step - loss: 0.0468 - val_loss: 0.0734\n",
      "Epoch 344/1000\n",
      "158/158 [==============================] - 0s 127us/step - loss: 0.0466 - val_loss: 0.0730\n",
      "Epoch 345/1000\n",
      "158/158 [==============================] - 0s 142us/step - loss: 0.0463 - val_loss: 0.0727\n",
      "Epoch 346/1000\n",
      "158/158 [==============================] - 0s 145us/step - loss: 0.0461 - val_loss: 0.0723\n",
      "Epoch 347/1000\n",
      "158/158 [==============================] - 0s 200us/step - loss: 0.0459 - val_loss: 0.0720\n",
      "Epoch 348/1000\n",
      "158/158 [==============================] - 0s 181us/step - loss: 0.0457 - val_loss: 0.0716\n",
      "Epoch 349/1000\n",
      "158/158 [==============================] - 0s 152us/step - loss: 0.0454 - val_loss: 0.0713\n",
      "Epoch 350/1000\n",
      "158/158 [==============================] - 0s 163us/step - loss: 0.0452 - val_loss: 0.0710\n",
      "Epoch 351/1000\n",
      "158/158 [==============================] - 0s 150us/step - loss: 0.0450 - val_loss: 0.0706\n",
      "Epoch 352/1000\n",
      "158/158 [==============================] - 0s 159us/step - loss: 0.0448 - val_loss: 0.0703\n",
      "Epoch 353/1000\n",
      "158/158 [==============================] - 0s 176us/step - loss: 0.0446 - val_loss: 0.0700\n",
      "Epoch 354/1000\n",
      "158/158 [==============================] - 0s 151us/step - loss: 0.0444 - val_loss: 0.0697\n",
      "Epoch 355/1000\n",
      "158/158 [==============================] - 0s 149us/step - loss: 0.0442 - val_loss: 0.0694\n",
      "Epoch 356/1000\n",
      "158/158 [==============================] - 0s 131us/step - loss: 0.0440 - val_loss: 0.0690\n",
      "Epoch 357/1000\n",
      "158/158 [==============================] - 0s 150us/step - loss: 0.0438 - val_loss: 0.0687\n",
      "Epoch 358/1000\n",
      "158/158 [==============================] - 0s 204us/step - loss: 0.0436 - val_loss: 0.0684\n",
      "Epoch 359/1000\n",
      "158/158 [==============================] - 0s 168us/step - loss: 0.0435 - val_loss: 0.0681\n",
      "Epoch 360/1000\n",
      "158/158 [==============================] - 0s 144us/step - loss: 0.0433 - val_loss: 0.0678\n",
      "Epoch 361/1000\n",
      "158/158 [==============================] - 0s 158us/step - loss: 0.0431 - val_loss: 0.0675\n",
      "Epoch 362/1000\n",
      "158/158 [==============================] - 0s 224us/step - loss: 0.0429 - val_loss: 0.0672\n",
      "Epoch 363/1000\n",
      "158/158 [==============================] - 0s 185us/step - loss: 0.0428 - val_loss: 0.0669\n",
      "Epoch 364/1000\n",
      "158/158 [==============================] - 0s 197us/step - loss: 0.0426 - val_loss: 0.0666\n",
      "Epoch 365/1000\n",
      "158/158 [==============================] - 0s 178us/step - loss: 0.0424 - val_loss: 0.0663\n",
      "Epoch 366/1000\n",
      "158/158 [==============================] - 0s 122us/step - loss: 0.0422 - val_loss: 0.0661\n",
      "Epoch 367/1000\n",
      "158/158 [==============================] - 0s 153us/step - loss: 0.0421 - val_loss: 0.0658\n",
      "Epoch 368/1000\n",
      "158/158 [==============================] - 0s 146us/step - loss: 0.0419 - val_loss: 0.0655\n",
      "Epoch 369/1000\n",
      "158/158 [==============================] - 0s 152us/step - loss: 0.0418 - val_loss: 0.0652\n",
      "Epoch 370/1000\n",
      "158/158 [==============================] - 0s 135us/step - loss: 0.0416 - val_loss: 0.0650\n",
      "Epoch 371/1000\n",
      "158/158 [==============================] - 0s 183us/step - loss: 0.0415 - val_loss: 0.0647\n",
      "Epoch 372/1000\n",
      "158/158 [==============================] - 0s 137us/step - loss: 0.0413 - val_loss: 0.0644\n",
      "Epoch 373/1000\n",
      "158/158 [==============================] - 0s 152us/step - loss: 0.0411 - val_loss: 0.0642\n",
      "Epoch 374/1000\n",
      "158/158 [==============================] - 0s 173us/step - loss: 0.0410 - val_loss: 0.0639\n",
      "Epoch 375/1000\n",
      "158/158 [==============================] - 0s 147us/step - loss: 0.0409 - val_loss: 0.0636\n",
      "Epoch 376/1000\n",
      "158/158 [==============================] - 0s 128us/step - loss: 0.0407 - val_loss: 0.0634\n",
      "Epoch 377/1000\n",
      "158/158 [==============================] - 0s 112us/step - loss: 0.0406 - val_loss: 0.0631\n",
      "Epoch 378/1000\n",
      "158/158 [==============================] - 0s 123us/step - loss: 0.0404 - val_loss: 0.0629\n",
      "Epoch 379/1000\n",
      "158/158 [==============================] - 0s 141us/step - loss: 0.0403 - val_loss: 0.0626\n",
      "Epoch 380/1000\n",
      "158/158 [==============================] - 0s 178us/step - loss: 0.0401 - val_loss: 0.0624\n",
      "Epoch 381/1000\n",
      "158/158 [==============================] - 0s 167us/step - loss: 0.0400 - val_loss: 0.0622\n",
      "Epoch 382/1000\n",
      "158/158 [==============================] - 0s 154us/step - loss: 0.0399 - val_loss: 0.0619\n",
      "Epoch 383/1000\n",
      "158/158 [==============================] - 0s 123us/step - loss: 0.0397 - val_loss: 0.0617\n",
      "Epoch 384/1000\n",
      "158/158 [==============================] - 0s 200us/step - loss: 0.0396 - val_loss: 0.0615\n",
      "Epoch 385/1000\n",
      "158/158 [==============================] - 0s 194us/step - loss: 0.0395 - val_loss: 0.0612\n",
      "Epoch 386/1000\n",
      "158/158 [==============================] - 0s 170us/step - loss: 0.0393 - val_loss: 0.0610\n",
      "Epoch 387/1000\n",
      "158/158 [==============================] - 0s 170us/step - loss: 0.0392 - val_loss: 0.0608\n",
      "Epoch 388/1000\n",
      "158/158 [==============================] - 0s 125us/step - loss: 0.0391 - val_loss: 0.0606\n",
      "Epoch 389/1000\n",
      "158/158 [==============================] - 0s 138us/step - loss: 0.0390 - val_loss: 0.0604\n",
      "Epoch 390/1000\n",
      "158/158 [==============================] - 0s 147us/step - loss: 0.0388 - val_loss: 0.0602\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 391/1000\n",
      "158/158 [==============================] - 0s 146us/step - loss: 0.0387 - val_loss: 0.0599\n",
      "Epoch 392/1000\n",
      "158/158 [==============================] - 0s 149us/step - loss: 0.0386 - val_loss: 0.0597\n",
      "Epoch 393/1000\n",
      "158/158 [==============================] - 0s 138us/step - loss: 0.0385 - val_loss: 0.0595\n",
      "Epoch 394/1000\n",
      "158/158 [==============================] - 0s 152us/step - loss: 0.0384 - val_loss: 0.0593\n",
      "Epoch 395/1000\n",
      "158/158 [==============================] - 0s 222us/step - loss: 0.0382 - val_loss: 0.0591\n",
      "Epoch 396/1000\n",
      "158/158 [==============================] - 0s 176us/step - loss: 0.0381 - val_loss: 0.0589\n",
      "Epoch 397/1000\n",
      "158/158 [==============================] - 0s 127us/step - loss: 0.0380 - val_loss: 0.0587\n",
      "Epoch 398/1000\n",
      "158/158 [==============================] - 0s 161us/step - loss: 0.0379 - val_loss: 0.0586\n",
      "Epoch 399/1000\n",
      "158/158 [==============================] - 0s 151us/step - loss: 0.0378 - val_loss: 0.0584\n",
      "Epoch 400/1000\n",
      "158/158 [==============================] - 0s 144us/step - loss: 0.0377 - val_loss: 0.0582\n",
      "Epoch 401/1000\n",
      "158/158 [==============================] - 0s 173us/step - loss: 0.0375 - val_loss: 0.0580\n",
      "Epoch 402/1000\n",
      "158/158 [==============================] - 0s 139us/step - loss: 0.0374 - val_loss: 0.0578\n",
      "Epoch 403/1000\n",
      "158/158 [==============================] - 0s 172us/step - loss: 0.0373 - val_loss: 0.0576\n",
      "Epoch 404/1000\n",
      "158/158 [==============================] - 0s 158us/step - loss: 0.0372 - val_loss: 0.0575\n",
      "Epoch 405/1000\n",
      "158/158 [==============================] - 0s 140us/step - loss: 0.0371 - val_loss: 0.0573\n",
      "Epoch 406/1000\n",
      "158/158 [==============================] - 0s 148us/step - loss: 0.0370 - val_loss: 0.0571\n",
      "Epoch 407/1000\n",
      "158/158 [==============================] - 0s 169us/step - loss: 0.0369 - val_loss: 0.0570\n",
      "Epoch 408/1000\n",
      "158/158 [==============================] - 0s 187us/step - loss: 0.0368 - val_loss: 0.0568\n",
      "Epoch 409/1000\n",
      "158/158 [==============================] - 0s 176us/step - loss: 0.0367 - val_loss: 0.0566\n",
      "Epoch 410/1000\n",
      "158/158 [==============================] - 0s 143us/step - loss: 0.0366 - val_loss: 0.0565\n",
      "Epoch 411/1000\n",
      "158/158 [==============================] - 0s 130us/step - loss: 0.0365 - val_loss: 0.0563\n",
      "Epoch 412/1000\n",
      "158/158 [==============================] - 0s 130us/step - loss: 0.0364 - val_loss: 0.0562\n",
      "Epoch 413/1000\n",
      "158/158 [==============================] - 0s 168us/step - loss: 0.0363 - val_loss: 0.0560\n",
      "Epoch 414/1000\n",
      "158/158 [==============================] - 0s 142us/step - loss: 0.0362 - val_loss: 0.0558\n",
      "Epoch 415/1000\n",
      "158/158 [==============================] - 0s 141us/step - loss: 0.0361 - val_loss: 0.0557\n",
      "Epoch 416/1000\n",
      "158/158 [==============================] - 0s 148us/step - loss: 0.0360 - val_loss: 0.0555\n",
      "Epoch 417/1000\n",
      "158/158 [==============================] - 0s 151us/step - loss: 0.0359 - val_loss: 0.0554\n",
      "Epoch 418/1000\n",
      "158/158 [==============================] - 0s 177us/step - loss: 0.0358 - val_loss: 0.0553\n",
      "Epoch 419/1000\n",
      "158/158 [==============================] - 0s 151us/step - loss: 0.0357 - val_loss: 0.0551\n",
      "Epoch 420/1000\n",
      "158/158 [==============================] - 0s 144us/step - loss: 0.0356 - val_loss: 0.0550\n",
      "Epoch 421/1000\n",
      "158/158 [==============================] - 0s 140us/step - loss: 0.0355 - val_loss: 0.0548\n",
      "Epoch 422/1000\n",
      "158/158 [==============================] - 0s 174us/step - loss: 0.0354 - val_loss: 0.0547\n",
      "Epoch 423/1000\n",
      "158/158 [==============================] - 0s 140us/step - loss: 0.0353 - val_loss: 0.0546\n",
      "Epoch 424/1000\n",
      "158/158 [==============================] - 0s 143us/step - loss: 0.0352 - val_loss: 0.0544\n",
      "Epoch 425/1000\n",
      "158/158 [==============================] - 0s 166us/step - loss: 0.0351 - val_loss: 0.0543\n",
      "Epoch 426/1000\n",
      "158/158 [==============================] - 0s 162us/step - loss: 0.0350 - val_loss: 0.0542\n",
      "Epoch 427/1000\n",
      "158/158 [==============================] - 0s 172us/step - loss: 0.0349 - val_loss: 0.0541\n",
      "Epoch 428/1000\n",
      "158/158 [==============================] - 0s 150us/step - loss: 0.0348 - val_loss: 0.0539\n",
      "Epoch 429/1000\n",
      "158/158 [==============================] - 0s 164us/step - loss: 0.0347 - val_loss: 0.0538\n",
      "Epoch 430/1000\n",
      "158/158 [==============================] - 0s 193us/step - loss: 0.0346 - val_loss: 0.0537\n",
      "Epoch 431/1000\n",
      "158/158 [==============================] - 0s 156us/step - loss: 0.0345 - val_loss: 0.0536\n",
      "Epoch 432/1000\n",
      "158/158 [==============================] - 0s 164us/step - loss: 0.0345 - val_loss: 0.0535\n",
      "Epoch 433/1000\n",
      "158/158 [==============================] - 0s 186us/step - loss: 0.0344 - val_loss: 0.0533\n",
      "Epoch 434/1000\n",
      "158/158 [==============================] - 0s 148us/step - loss: 0.0343 - val_loss: 0.0532\n",
      "Epoch 435/1000\n",
      "158/158 [==============================] - 0s 142us/step - loss: 0.0342 - val_loss: 0.0531\n",
      "Epoch 436/1000\n",
      "158/158 [==============================] - 0s 129us/step - loss: 0.0341 - val_loss: 0.0530\n",
      "Epoch 437/1000\n",
      "158/158 [==============================] - 0s 150us/step - loss: 0.0340 - val_loss: 0.0529\n",
      "Epoch 438/1000\n",
      "158/158 [==============================] - 0s 173us/step - loss: 0.0339 - val_loss: 0.0528\n",
      "Epoch 439/1000\n",
      "158/158 [==============================] - 0s 201us/step - loss: 0.0338 - val_loss: 0.0527\n",
      "Epoch 440/1000\n",
      "158/158 [==============================] - 0s 204us/step - loss: 0.0338 - val_loss: 0.0526\n",
      "Epoch 441/1000\n",
      "158/158 [==============================] - 0s 150us/step - loss: 0.0337 - val_loss: 0.0525\n",
      "Epoch 442/1000\n",
      "158/158 [==============================] - 0s 152us/step - loss: 0.0336 - val_loss: 0.0524\n",
      "Epoch 443/1000\n",
      "158/158 [==============================] - 0s 170us/step - loss: 0.0335 - val_loss: 0.0523\n",
      "Epoch 444/1000\n",
      "158/158 [==============================] - 0s 154us/step - loss: 0.0334 - val_loss: 0.0522\n",
      "Epoch 445/1000\n",
      "158/158 [==============================] - 0s 154us/step - loss: 0.0333 - val_loss: 0.0521\n",
      "Epoch 446/1000\n",
      "158/158 [==============================] - 0s 114us/step - loss: 0.0333 - val_loss: 0.0520\n",
      "Epoch 447/1000\n",
      "158/158 [==============================] - 0s 136us/step - loss: 0.0332 - val_loss: 0.0519\n",
      "Epoch 448/1000\n",
      "158/158 [==============================] - 0s 146us/step - loss: 0.0331 - val_loss: 0.0518\n",
      "Epoch 449/1000\n",
      "158/158 [==============================] - 0s 116us/step - loss: 0.0330 - val_loss: 0.0517\n",
      "Epoch 450/1000\n",
      "158/158 [==============================] - 0s 138us/step - loss: 0.0329 - val_loss: 0.0516\n",
      "Epoch 451/1000\n",
      "158/158 [==============================] - 0s 172us/step - loss: 0.0329 - val_loss: 0.0515\n",
      "Epoch 452/1000\n",
      "158/158 [==============================] - 0s 238us/step - loss: 0.0328 - val_loss: 0.0514\n",
      "Epoch 453/1000\n",
      "158/158 [==============================] - 0s 183us/step - loss: 0.0327 - val_loss: 0.0513\n",
      "Epoch 454/1000\n",
      "158/158 [==============================] - 0s 123us/step - loss: 0.0326 - val_loss: 0.0512\n",
      "Epoch 455/1000\n",
      "158/158 [==============================] - 0s 132us/step - loss: 0.0325 - val_loss: 0.0512\n",
      "Epoch 456/1000\n",
      "158/158 [==============================] - 0s 137us/step - loss: 0.0325 - val_loss: 0.0511\n",
      "Epoch 457/1000\n",
      "158/158 [==============================] - 0s 127us/step - loss: 0.0324 - val_loss: 0.0510\n",
      "Epoch 458/1000\n",
      "158/158 [==============================] - 0s 168us/step - loss: 0.0323 - val_loss: 0.0509\n",
      "Epoch 459/1000\n",
      "158/158 [==============================] - 0s 145us/step - loss: 0.0322 - val_loss: 0.0508\n",
      "Epoch 460/1000\n",
      "158/158 [==============================] - 0s 146us/step - loss: 0.0322 - val_loss: 0.0507\n",
      "Epoch 461/1000\n",
      "158/158 [==============================] - 0s 166us/step - loss: 0.0321 - val_loss: 0.0506\n",
      "Epoch 462/1000\n",
      "158/158 [==============================] - 0s 157us/step - loss: 0.0320 - val_loss: 0.0506\n",
      "Epoch 463/1000\n",
      "158/158 [==============================] - 0s 201us/step - loss: 0.0319 - val_loss: 0.0505\n",
      "Epoch 464/1000\n",
      "158/158 [==============================] - 0s 148us/step - loss: 0.0319 - val_loss: 0.0504\n",
      "Epoch 465/1000\n",
      "158/158 [==============================] - 0s 167us/step - loss: 0.0318 - val_loss: 0.0503\n",
      "Epoch 466/1000\n",
      "158/158 [==============================] - 0s 169us/step - loss: 0.0317 - val_loss: 0.0503\n",
      "Epoch 467/1000\n",
      "158/158 [==============================] - 0s 151us/step - loss: 0.0316 - val_loss: 0.0502\n",
      "Epoch 468/1000\n",
      "158/158 [==============================] - 0s 151us/step - loss: 0.0316 - val_loss: 0.0501\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 469/1000\n",
      "158/158 [==============================] - 0s 163us/step - loss: 0.0315 - val_loss: 0.0500\n",
      "Epoch 470/1000\n",
      "158/158 [==============================] - 0s 161us/step - loss: 0.0314 - val_loss: 0.0500\n",
      "Epoch 471/1000\n",
      "158/158 [==============================] - 0s 122us/step - loss: 0.0313 - val_loss: 0.0499\n",
      "Epoch 472/1000\n",
      "158/158 [==============================] - 0s 130us/step - loss: 0.0313 - val_loss: 0.0498\n",
      "Epoch 473/1000\n",
      "158/158 [==============================] - 0s 168us/step - loss: 0.0312 - val_loss: 0.0497\n",
      "Epoch 474/1000\n",
      "158/158 [==============================] - 0s 159us/step - loss: 0.0311 - val_loss: 0.0497\n",
      "Epoch 475/1000\n",
      "158/158 [==============================] - 0s 116us/step - loss: 0.0311 - val_loss: 0.0496\n",
      "Epoch 476/1000\n",
      "158/158 [==============================] - 0s 171us/step - loss: 0.0310 - val_loss: 0.0495\n",
      "Epoch 477/1000\n",
      "158/158 [==============================] - 0s 136us/step - loss: 0.0309 - val_loss: 0.0495\n",
      "Epoch 478/1000\n",
      "158/158 [==============================] - 0s 128us/step - loss: 0.0309 - val_loss: 0.0494\n",
      "Epoch 479/1000\n",
      "158/158 [==============================] - 0s 207us/step - loss: 0.0308 - val_loss: 0.0493\n",
      "Epoch 480/1000\n",
      "158/158 [==============================] - 0s 157us/step - loss: 0.0307 - val_loss: 0.0492\n",
      "Epoch 481/1000\n",
      "158/158 [==============================] - 0s 148us/step - loss: 0.0306 - val_loss: 0.0492\n",
      "Epoch 482/1000\n",
      "158/158 [==============================] - 0s 154us/step - loss: 0.0306 - val_loss: 0.0491\n",
      "Epoch 483/1000\n",
      "158/158 [==============================] - 0s 134us/step - loss: 0.0305 - val_loss: 0.0490\n",
      "Epoch 484/1000\n",
      "158/158 [==============================] - 0s 139us/step - loss: 0.0304 - val_loss: 0.0490\n",
      "Epoch 485/1000\n",
      "158/158 [==============================] - 0s 141us/step - loss: 0.0304 - val_loss: 0.0489\n",
      "Epoch 486/1000\n",
      "158/158 [==============================] - 0s 180us/step - loss: 0.0303 - val_loss: 0.0488\n",
      "Epoch 487/1000\n",
      "158/158 [==============================] - 0s 175us/step - loss: 0.0302 - val_loss: 0.0488\n",
      "Epoch 488/1000\n",
      "158/158 [==============================] - 0s 150us/step - loss: 0.0302 - val_loss: 0.0487\n",
      "Epoch 489/1000\n",
      "158/158 [==============================] - 0s 105us/step - loss: 0.0301 - val_loss: 0.0487\n",
      "Epoch 490/1000\n",
      "158/158 [==============================] - 0s 158us/step - loss: 0.0300 - val_loss: 0.0486\n",
      "Epoch 491/1000\n",
      "158/158 [==============================] - 0s 141us/step - loss: 0.0300 - val_loss: 0.0485\n",
      "Epoch 492/1000\n",
      "158/158 [==============================] - 0s 128us/step - loss: 0.0299 - val_loss: 0.0485\n",
      "Epoch 493/1000\n",
      "158/158 [==============================] - 0s 166us/step - loss: 0.0298 - val_loss: 0.0484\n",
      "Epoch 494/1000\n",
      "158/158 [==============================] - 0s 135us/step - loss: 0.0298 - val_loss: 0.0483\n",
      "Epoch 495/1000\n",
      "158/158 [==============================] - 0s 157us/step - loss: 0.0297 - val_loss: 0.0483\n",
      "Epoch 496/1000\n",
      "158/158 [==============================] - 0s 131us/step - loss: 0.0297 - val_loss: 0.0482\n",
      "Epoch 497/1000\n",
      "158/158 [==============================] - 0s 190us/step - loss: 0.0296 - val_loss: 0.0482\n",
      "Epoch 498/1000\n",
      "158/158 [==============================] - 0s 149us/step - loss: 0.0295 - val_loss: 0.0481\n",
      "Epoch 499/1000\n",
      "158/158 [==============================] - 0s 159us/step - loss: 0.0295 - val_loss: 0.0480\n",
      "Epoch 500/1000\n",
      "158/158 [==============================] - 0s 120us/step - loss: 0.0294 - val_loss: 0.0480\n",
      "Epoch 501/1000\n",
      "158/158 [==============================] - 0s 145us/step - loss: 0.0293 - val_loss: 0.0479\n",
      "Epoch 502/1000\n",
      "158/158 [==============================] - 0s 137us/step - loss: 0.0293 - val_loss: 0.0479\n",
      "Epoch 503/1000\n",
      "158/158 [==============================] - 0s 136us/step - loss: 0.0292 - val_loss: 0.0478\n",
      "Epoch 504/1000\n",
      "158/158 [==============================] - 0s 169us/step - loss: 0.0291 - val_loss: 0.0477\n",
      "Epoch 505/1000\n",
      "158/158 [==============================] - 0s 149us/step - loss: 0.0291 - val_loss: 0.0477\n",
      "Epoch 506/1000\n",
      "158/158 [==============================] - 0s 163us/step - loss: 0.0290 - val_loss: 0.0476\n",
      "Epoch 507/1000\n",
      "158/158 [==============================] - 0s 173us/step - loss: 0.0290 - val_loss: 0.0476\n",
      "Epoch 508/1000\n",
      "158/158 [==============================] - 0s 152us/step - loss: 0.0289 - val_loss: 0.0475\n",
      "Epoch 509/1000\n",
      "158/158 [==============================] - 0s 149us/step - loss: 0.0288 - val_loss: 0.0475\n",
      "Epoch 510/1000\n",
      "158/158 [==============================] - 0s 160us/step - loss: 0.0288 - val_loss: 0.0474\n",
      "Epoch 511/1000\n",
      "158/158 [==============================] - 0s 152us/step - loss: 0.0287 - val_loss: 0.0473\n",
      "Epoch 512/1000\n",
      "158/158 [==============================] - 0s 176us/step - loss: 0.0287 - val_loss: 0.0473\n",
      "Epoch 513/1000\n",
      "158/158 [==============================] - 0s 188us/step - loss: 0.0286 - val_loss: 0.0472\n",
      "Epoch 514/1000\n",
      "158/158 [==============================] - 0s 163us/step - loss: 0.0285 - val_loss: 0.0472\n",
      "Epoch 515/1000\n",
      "158/158 [==============================] - 0s 175us/step - loss: 0.0285 - val_loss: 0.0471\n",
      "Epoch 516/1000\n",
      "158/158 [==============================] - 0s 150us/step - loss: 0.0284 - val_loss: 0.0471\n",
      "Epoch 517/1000\n",
      "158/158 [==============================] - 0s 157us/step - loss: 0.0284 - val_loss: 0.0470\n",
      "Epoch 518/1000\n",
      "158/158 [==============================] - 0s 162us/step - loss: 0.0283 - val_loss: 0.0470\n",
      "Epoch 519/1000\n",
      "158/158 [==============================] - 0s 166us/step - loss: 0.0282 - val_loss: 0.0469\n",
      "Epoch 520/1000\n",
      "158/158 [==============================] - 0s 188us/step - loss: 0.0282 - val_loss: 0.0469\n",
      "Epoch 521/1000\n",
      "158/158 [==============================] - 0s 175us/step - loss: 0.0281 - val_loss: 0.0468\n",
      "Epoch 522/1000\n",
      "158/158 [==============================] - 0s 177us/step - loss: 0.0281 - val_loss: 0.0467\n",
      "Epoch 523/1000\n",
      "158/158 [==============================] - 0s 146us/step - loss: 0.0280 - val_loss: 0.0467\n",
      "Epoch 524/1000\n",
      "158/158 [==============================] - 0s 142us/step - loss: 0.0279 - val_loss: 0.0466\n",
      "Epoch 525/1000\n",
      "158/158 [==============================] - 0s 162us/step - loss: 0.0279 - val_loss: 0.0466\n",
      "Epoch 526/1000\n",
      "158/158 [==============================] - 0s 164us/step - loss: 0.0278 - val_loss: 0.0465\n",
      "Epoch 527/1000\n",
      "158/158 [==============================] - 0s 144us/step - loss: 0.0278 - val_loss: 0.0465\n",
      "Epoch 528/1000\n",
      "158/158 [==============================] - 0s 161us/step - loss: 0.0277 - val_loss: 0.0464\n",
      "Epoch 529/1000\n",
      "158/158 [==============================] - 0s 212us/step - loss: 0.0277 - val_loss: 0.0464\n",
      "Epoch 530/1000\n",
      "158/158 [==============================] - 0s 193us/step - loss: 0.0276 - val_loss: 0.0463\n",
      "Epoch 531/1000\n",
      "158/158 [==============================] - 0s 181us/step - loss: 0.0276 - val_loss: 0.0463\n",
      "Epoch 532/1000\n",
      "158/158 [==============================] - 0s 160us/step - loss: 0.0275 - val_loss: 0.0462\n",
      "Epoch 533/1000\n",
      "158/158 [==============================] - 0s 170us/step - loss: 0.0274 - val_loss: 0.0462\n",
      "Epoch 534/1000\n",
      "158/158 [==============================] - 0s 158us/step - loss: 0.0274 - val_loss: 0.0461\n",
      "Epoch 535/1000\n",
      "158/158 [==============================] - 0s 128us/step - loss: 0.0273 - val_loss: 0.0461\n",
      "Epoch 536/1000\n",
      "158/158 [==============================] - 0s 172us/step - loss: 0.0273 - val_loss: 0.0460\n",
      "Epoch 537/1000\n",
      "158/158 [==============================] - 0s 152us/step - loss: 0.0272 - val_loss: 0.0460\n",
      "Epoch 538/1000\n",
      "158/158 [==============================] - 0s 197us/step - loss: 0.0272 - val_loss: 0.0459\n",
      "Epoch 539/1000\n",
      "158/158 [==============================] - 0s 183us/step - loss: 0.0271 - val_loss: 0.0459\n",
      "Epoch 540/1000\n",
      "158/158 [==============================] - 0s 163us/step - loss: 0.0271 - val_loss: 0.0458\n",
      "Epoch 541/1000\n",
      "158/158 [==============================] - 0s 159us/step - loss: 0.0270 - val_loss: 0.0458\n",
      "Epoch 542/1000\n",
      "158/158 [==============================] - 0s 146us/step - loss: 0.0269 - val_loss: 0.0457\n",
      "Epoch 543/1000\n",
      "158/158 [==============================] - 0s 144us/step - loss: 0.0269 - val_loss: 0.0457\n",
      "Epoch 544/1000\n",
      "158/158 [==============================] - 0s 164us/step - loss: 0.0268 - val_loss: 0.0456\n",
      "Epoch 545/1000\n",
      "158/158 [==============================] - 0s 133us/step - loss: 0.0268 - val_loss: 0.0456\n",
      "Epoch 546/1000\n",
      "158/158 [==============================] - 0s 113us/step - loss: 0.0267 - val_loss: 0.0455\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 547/1000\n",
      "158/158 [==============================] - 0s 143us/step - loss: 0.0267 - val_loss: 0.0455\n",
      "Epoch 548/1000\n",
      "158/158 [==============================] - 0s 135us/step - loss: 0.0266 - val_loss: 0.0454\n",
      "Epoch 549/1000\n",
      "158/158 [==============================] - 0s 164us/step - loss: 0.0266 - val_loss: 0.0454\n",
      "Epoch 550/1000\n",
      "158/158 [==============================] - 0s 180us/step - loss: 0.0265 - val_loss: 0.0453\n",
      "Epoch 551/1000\n",
      "158/158 [==============================] - 0s 190us/step - loss: 0.0265 - val_loss: 0.0453\n",
      "Epoch 552/1000\n",
      "158/158 [==============================] - 0s 145us/step - loss: 0.0264 - val_loss: 0.0452\n",
      "Epoch 553/1000\n",
      "158/158 [==============================] - 0s 182us/step - loss: 0.0264 - val_loss: 0.0452\n",
      "Epoch 554/1000\n",
      "158/158 [==============================] - 0s 132us/step - loss: 0.0263 - val_loss: 0.0451\n",
      "Epoch 555/1000\n",
      "158/158 [==============================] - 0s 140us/step - loss: 0.0263 - val_loss: 0.0451\n",
      "Epoch 556/1000\n",
      "158/158 [==============================] - 0s 163us/step - loss: 0.0262 - val_loss: 0.0450\n",
      "Epoch 557/1000\n",
      "158/158 [==============================] - 0s 147us/step - loss: 0.0262 - val_loss: 0.0450\n",
      "Epoch 558/1000\n",
      "158/158 [==============================] - 0s 147us/step - loss: 0.0261 - val_loss: 0.0449\n",
      "Epoch 559/1000\n",
      "158/158 [==============================] - 0s 133us/step - loss: 0.0260 - val_loss: 0.0449\n",
      "Epoch 560/1000\n",
      "158/158 [==============================] - 0s 135us/step - loss: 0.0260 - val_loss: 0.0448\n",
      "Epoch 561/1000\n",
      "158/158 [==============================] - 0s 153us/step - loss: 0.0259 - val_loss: 0.0448\n",
      "Epoch 562/1000\n",
      "158/158 [==============================] - 0s 193us/step - loss: 0.0259 - val_loss: 0.0447\n",
      "Epoch 563/1000\n",
      "158/158 [==============================] - 0s 162us/step - loss: 0.0258 - val_loss: 0.0447\n",
      "Epoch 564/1000\n",
      "158/158 [==============================] - 0s 111us/step - loss: 0.0258 - val_loss: 0.0446\n",
      "Epoch 565/1000\n",
      "158/158 [==============================] - 0s 173us/step - loss: 0.0257 - val_loss: 0.0446\n",
      "Epoch 566/1000\n",
      "158/158 [==============================] - 0s 155us/step - loss: 0.0257 - val_loss: 0.0445\n",
      "Epoch 567/1000\n",
      "158/158 [==============================] - 0s 143us/step - loss: 0.0256 - val_loss: 0.0445\n",
      "Epoch 568/1000\n",
      "158/158 [==============================] - 0s 153us/step - loss: 0.0256 - val_loss: 0.0445\n",
      "Epoch 569/1000\n",
      "158/158 [==============================] - 0s 128us/step - loss: 0.0255 - val_loss: 0.0444\n",
      "Epoch 570/1000\n",
      "158/158 [==============================] - 0s 142us/step - loss: 0.0255 - val_loss: 0.0444\n",
      "Epoch 571/1000\n",
      "158/158 [==============================] - 0s 172us/step - loss: 0.0254 - val_loss: 0.0443\n",
      "Epoch 572/1000\n",
      "158/158 [==============================] - 0s 172us/step - loss: 0.0254 - val_loss: 0.0443\n",
      "Epoch 573/1000\n",
      "158/158 [==============================] - 0s 149us/step - loss: 0.0253 - val_loss: 0.0442\n",
      "Epoch 574/1000\n",
      "158/158 [==============================] - 0s 175us/step - loss: 0.0253 - val_loss: 0.0442\n",
      "Epoch 575/1000\n",
      "158/158 [==============================] - 0s 184us/step - loss: 0.0252 - val_loss: 0.0441\n",
      "Epoch 576/1000\n",
      "158/158 [==============================] - 0s 128us/step - loss: 0.0252 - val_loss: 0.0441\n",
      "Epoch 577/1000\n",
      "158/158 [==============================] - 0s 147us/step - loss: 0.0252 - val_loss: 0.0440\n",
      "Epoch 578/1000\n",
      "158/158 [==============================] - 0s 139us/step - loss: 0.0251 - val_loss: 0.0440\n",
      "Epoch 579/1000\n",
      "158/158 [==============================] - 0s 131us/step - loss: 0.0251 - val_loss: 0.0439\n",
      "Epoch 580/1000\n",
      "158/158 [==============================] - 0s 113us/step - loss: 0.0250 - val_loss: 0.0439\n",
      "Epoch 581/1000\n",
      "158/158 [==============================] - 0s 179us/step - loss: 0.0250 - val_loss: 0.0439\n",
      "Epoch 582/1000\n",
      "158/158 [==============================] - 0s 155us/step - loss: 0.0249 - val_loss: 0.0438\n",
      "Epoch 583/1000\n",
      "158/158 [==============================] - 0s 155us/step - loss: 0.0249 - val_loss: 0.0438\n",
      "Epoch 584/1000\n",
      "158/158 [==============================] - 0s 192us/step - loss: 0.0248 - val_loss: 0.0437\n",
      "Epoch 585/1000\n",
      "158/158 [==============================] - 0s 172us/step - loss: 0.0248 - val_loss: 0.0437\n",
      "Epoch 586/1000\n",
      "158/158 [==============================] - 0s 179us/step - loss: 0.0247 - val_loss: 0.0436\n",
      "Epoch 587/1000\n",
      "158/158 [==============================] - 0s 158us/step - loss: 0.0247 - val_loss: 0.0436\n",
      "Epoch 588/1000\n",
      "158/158 [==============================] - 0s 146us/step - loss: 0.0246 - val_loss: 0.0435\n",
      "Epoch 589/1000\n",
      "158/158 [==============================] - 0s 170us/step - loss: 0.0246 - val_loss: 0.0435\n",
      "Epoch 590/1000\n",
      "158/158 [==============================] - 0s 169us/step - loss: 0.0245 - val_loss: 0.0434\n",
      "Epoch 591/1000\n",
      "158/158 [==============================] - 0s 144us/step - loss: 0.0245 - val_loss: 0.0434\n",
      "Epoch 592/1000\n",
      "158/158 [==============================] - 0s 167us/step - loss: 0.0244 - val_loss: 0.0434\n",
      "Epoch 593/1000\n",
      "158/158 [==============================] - 0s 149us/step - loss: 0.0244 - val_loss: 0.0433\n",
      "Epoch 594/1000\n",
      "158/158 [==============================] - 0s 156us/step - loss: 0.0243 - val_loss: 0.0433\n",
      "Epoch 595/1000\n",
      "158/158 [==============================] - 0s 205us/step - loss: 0.0243 - val_loss: 0.0432\n",
      "Epoch 596/1000\n",
      "158/158 [==============================] - 0s 192us/step - loss: 0.0243 - val_loss: 0.0432\n",
      "Epoch 597/1000\n",
      "158/158 [==============================] - 0s 218us/step - loss: 0.0242 - val_loss: 0.0431\n",
      "Epoch 598/1000\n",
      "158/158 [==============================] - 0s 182us/step - loss: 0.0242 - val_loss: 0.0431\n",
      "Epoch 599/1000\n",
      "158/158 [==============================] - 0s 169us/step - loss: 0.0241 - val_loss: 0.0430\n",
      "Epoch 600/1000\n",
      "158/158 [==============================] - 0s 156us/step - loss: 0.0241 - val_loss: 0.0430\n",
      "Epoch 601/1000\n",
      "158/158 [==============================] - 0s 169us/step - loss: 0.0240 - val_loss: 0.0430\n",
      "Epoch 602/1000\n",
      "158/158 [==============================] - 0s 183us/step - loss: 0.0240 - val_loss: 0.0429\n",
      "Epoch 603/1000\n",
      "158/158 [==============================] - 0s 148us/step - loss: 0.0239 - val_loss: 0.0429\n",
      "Epoch 604/1000\n",
      "158/158 [==============================] - 0s 150us/step - loss: 0.0239 - val_loss: 0.0428\n",
      "Epoch 605/1000\n",
      "158/158 [==============================] - 0s 135us/step - loss: 0.0239 - val_loss: 0.0428\n",
      "Epoch 606/1000\n",
      "158/158 [==============================] - 0s 112us/step - loss: 0.0238 - val_loss: 0.0427\n",
      "Epoch 607/1000\n",
      "158/158 [==============================] - 0s 118us/step - loss: 0.0238 - val_loss: 0.0427\n",
      "Epoch 608/1000\n",
      "158/158 [==============================] - 0s 215us/step - loss: 0.0237 - val_loss: 0.0426\n",
      "Epoch 609/1000\n",
      "158/158 [==============================] - 0s 175us/step - loss: 0.0237 - val_loss: 0.0426\n",
      "Epoch 610/1000\n",
      "158/158 [==============================] - 0s 140us/step - loss: 0.0236 - val_loss: 0.0426\n",
      "Epoch 611/1000\n",
      "158/158 [==============================] - 0s 193us/step - loss: 0.0236 - val_loss: 0.0425\n",
      "Epoch 612/1000\n",
      "158/158 [==============================] - 0s 131us/step - loss: 0.0235 - val_loss: 0.0425\n",
      "Epoch 613/1000\n",
      "158/158 [==============================] - 0s 141us/step - loss: 0.0235 - val_loss: 0.0424\n",
      "Epoch 614/1000\n",
      "158/158 [==============================] - 0s 138us/step - loss: 0.0235 - val_loss: 0.0424\n",
      "Epoch 615/1000\n",
      "158/158 [==============================] - 0s 173us/step - loss: 0.0234 - val_loss: 0.0423\n",
      "Epoch 616/1000\n",
      "158/158 [==============================] - 0s 171us/step - loss: 0.0234 - val_loss: 0.0423\n",
      "Epoch 617/1000\n",
      "158/158 [==============================] - 0s 151us/step - loss: 0.0233 - val_loss: 0.0423\n",
      "Epoch 618/1000\n",
      "158/158 [==============================] - 0s 110us/step - loss: 0.0233 - val_loss: 0.0422\n",
      "Epoch 619/1000\n",
      "158/158 [==============================] - 0s 175us/step - loss: 0.0232 - val_loss: 0.0422\n",
      "Epoch 620/1000\n",
      "158/158 [==============================] - 0s 160us/step - loss: 0.0232 - val_loss: 0.0421\n",
      "Epoch 621/1000\n",
      "158/158 [==============================] - 0s 152us/step - loss: 0.0232 - val_loss: 0.0421\n",
      "Epoch 622/1000\n",
      "158/158 [==============================] - 0s 147us/step - loss: 0.0231 - val_loss: 0.0420\n",
      "Epoch 623/1000\n",
      "158/158 [==============================] - 0s 139us/step - loss: 0.0231 - val_loss: 0.0420\n",
      "Epoch 624/1000\n",
      "158/158 [==============================] - 0s 131us/step - loss: 0.0230 - val_loss: 0.0420\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 625/1000\n",
      "158/158 [==============================] - 0s 163us/step - loss: 0.0230 - val_loss: 0.0419\n",
      "Epoch 626/1000\n",
      "158/158 [==============================] - 0s 142us/step - loss: 0.0229 - val_loss: 0.0419\n",
      "Epoch 627/1000\n",
      "158/158 [==============================] - 0s 154us/step - loss: 0.0229 - val_loss: 0.0418\n",
      "Epoch 628/1000\n",
      "158/158 [==============================] - 0s 145us/step - loss: 0.0229 - val_loss: 0.0418\n",
      "Epoch 629/1000\n",
      "158/158 [==============================] - 0s 173us/step - loss: 0.0228 - val_loss: 0.0417\n",
      "Epoch 630/1000\n",
      "158/158 [==============================] - 0s 144us/step - loss: 0.0228 - val_loss: 0.0417\n",
      "Epoch 631/1000\n",
      "158/158 [==============================] - 0s 204us/step - loss: 0.0227 - val_loss: 0.0417\n",
      "Epoch 632/1000\n",
      "158/158 [==============================] - 0s 141us/step - loss: 0.0227 - val_loss: 0.0416\n",
      "Epoch 633/1000\n",
      "158/158 [==============================] - 0s 184us/step - loss: 0.0227 - val_loss: 0.0416\n",
      "Epoch 634/1000\n",
      "158/158 [==============================] - 0s 143us/step - loss: 0.0226 - val_loss: 0.0415\n",
      "Epoch 635/1000\n",
      "158/158 [==============================] - 0s 158us/step - loss: 0.0226 - val_loss: 0.0415\n",
      "Epoch 636/1000\n",
      "158/158 [==============================] - 0s 179us/step - loss: 0.0225 - val_loss: 0.0415\n",
      "Epoch 637/1000\n",
      "158/158 [==============================] - 0s 149us/step - loss: 0.0225 - val_loss: 0.0414\n",
      "Epoch 638/1000\n",
      "158/158 [==============================] - 0s 144us/step - loss: 0.0225 - val_loss: 0.0414\n",
      "Epoch 639/1000\n",
      "158/158 [==============================] - 0s 140us/step - loss: 0.0224 - val_loss: 0.0413\n",
      "Epoch 640/1000\n",
      "158/158 [==============================] - 0s 123us/step - loss: 0.0224 - val_loss: 0.0413\n",
      "Epoch 641/1000\n",
      "158/158 [==============================] - 0s 211us/step - loss: 0.0223 - val_loss: 0.0412\n",
      "Epoch 642/1000\n",
      "158/158 [==============================] - 0s 177us/step - loss: 0.0223 - val_loss: 0.0412\n",
      "Epoch 643/1000\n",
      "158/158 [==============================] - 0s 207us/step - loss: 0.0223 - val_loss: 0.0412\n",
      "Epoch 644/1000\n",
      "158/158 [==============================] - 0s 160us/step - loss: 0.0222 - val_loss: 0.0411\n",
      "Epoch 645/1000\n",
      "158/158 [==============================] - 0s 154us/step - loss: 0.0222 - val_loss: 0.0411\n",
      "Epoch 646/1000\n",
      "158/158 [==============================] - 0s 135us/step - loss: 0.0221 - val_loss: 0.0410\n",
      "Epoch 647/1000\n",
      "158/158 [==============================] - 0s 177us/step - loss: 0.0221 - val_loss: 0.0410\n",
      "Epoch 648/1000\n",
      "158/158 [==============================] - 0s 151us/step - loss: 0.0221 - val_loss: 0.0410\n",
      "Epoch 649/1000\n",
      "158/158 [==============================] - 0s 145us/step - loss: 0.0220 - val_loss: 0.0409\n",
      "Epoch 650/1000\n",
      "158/158 [==============================] - 0s 134us/step - loss: 0.0220 - val_loss: 0.0409\n",
      "Epoch 651/1000\n",
      "158/158 [==============================] - 0s 139us/step - loss: 0.0219 - val_loss: 0.0408\n",
      "Epoch 652/1000\n",
      "158/158 [==============================] - 0s 158us/step - loss: 0.0219 - val_loss: 0.0408\n",
      "Epoch 653/1000\n",
      "158/158 [==============================] - 0s 140us/step - loss: 0.0219 - val_loss: 0.0408\n",
      "Epoch 654/1000\n",
      "158/158 [==============================] - 0s 161us/step - loss: 0.0218 - val_loss: 0.0407\n",
      "Epoch 655/1000\n",
      "158/158 [==============================] - 0s 189us/step - loss: 0.0218 - val_loss: 0.0407\n",
      "Epoch 656/1000\n",
      "158/158 [==============================] - 0s 140us/step - loss: 0.0218 - val_loss: 0.0406\n",
      "Epoch 657/1000\n",
      "158/158 [==============================] - 0s 153us/step - loss: 0.0217 - val_loss: 0.0406\n",
      "Epoch 658/1000\n",
      "158/158 [==============================] - 0s 127us/step - loss: 0.0217 - val_loss: 0.0406\n",
      "Epoch 659/1000\n",
      "158/158 [==============================] - 0s 141us/step - loss: 0.0216 - val_loss: 0.0405\n",
      "Epoch 660/1000\n",
      "158/158 [==============================] - 0s 134us/step - loss: 0.0216 - val_loss: 0.0405\n",
      "Epoch 661/1000\n",
      "158/158 [==============================] - 0s 124us/step - loss: 0.0216 - val_loss: 0.0404\n",
      "Epoch 662/1000\n",
      "158/158 [==============================] - 0s 175us/step - loss: 0.0215 - val_loss: 0.0404\n",
      "Epoch 663/1000\n",
      "158/158 [==============================] - 0s 188us/step - loss: 0.0215 - val_loss: 0.0404\n",
      "Epoch 664/1000\n",
      "158/158 [==============================] - 0s 132us/step - loss: 0.0215 - val_loss: 0.0403\n",
      "Epoch 665/1000\n",
      "158/158 [==============================] - 0s 187us/step - loss: 0.0214 - val_loss: 0.0403\n",
      "Epoch 666/1000\n",
      "158/158 [==============================] - 0s 187us/step - loss: 0.0214 - val_loss: 0.0402\n",
      "Epoch 667/1000\n",
      "158/158 [==============================] - 0s 154us/step - loss: 0.0214 - val_loss: 0.0402\n",
      "Epoch 668/1000\n",
      "158/158 [==============================] - 0s 149us/step - loss: 0.0213 - val_loss: 0.0402\n",
      "Epoch 669/1000\n",
      "158/158 [==============================] - 0s 120us/step - loss: 0.0213 - val_loss: 0.0401\n",
      "Epoch 670/1000\n",
      "158/158 [==============================] - 0s 146us/step - loss: 0.0212 - val_loss: 0.0401\n",
      "Epoch 671/1000\n",
      "158/158 [==============================] - 0s 178us/step - loss: 0.0212 - val_loss: 0.0400\n",
      "Epoch 672/1000\n",
      "158/158 [==============================] - 0s 165us/step - loss: 0.0212 - val_loss: 0.0400\n",
      "Epoch 673/1000\n",
      "158/158 [==============================] - 0s 142us/step - loss: 0.0211 - val_loss: 0.0400\n",
      "Epoch 674/1000\n",
      "158/158 [==============================] - 0s 167us/step - loss: 0.0211 - val_loss: 0.0399\n",
      "Epoch 675/1000\n",
      "158/158 [==============================] - 0s 124us/step - loss: 0.0211 - val_loss: 0.0399\n",
      "Epoch 676/1000\n",
      "158/158 [==============================] - 0s 140us/step - loss: 0.0210 - val_loss: 0.0398\n",
      "Epoch 677/1000\n",
      "158/158 [==============================] - 0s 188us/step - loss: 0.0210 - val_loss: 0.0398\n",
      "Epoch 678/1000\n",
      "158/158 [==============================] - 0s 166us/step - loss: 0.0210 - val_loss: 0.0398\n",
      "Epoch 679/1000\n",
      "158/158 [==============================] - 0s 155us/step - loss: 0.0209 - val_loss: 0.0397\n",
      "Epoch 680/1000\n",
      "158/158 [==============================] - 0s 172us/step - loss: 0.0209 - val_loss: 0.0397\n",
      "Epoch 681/1000\n",
      "158/158 [==============================] - 0s 172us/step - loss: 0.0209 - val_loss: 0.0396\n",
      "Epoch 682/1000\n",
      "158/158 [==============================] - 0s 156us/step - loss: 0.0208 - val_loss: 0.0396\n",
      "Epoch 683/1000\n",
      "158/158 [==============================] - 0s 141us/step - loss: 0.0208 - val_loss: 0.0396\n",
      "Epoch 684/1000\n",
      "158/158 [==============================] - 0s 150us/step - loss: 0.0208 - val_loss: 0.0395\n",
      "Epoch 685/1000\n",
      "158/158 [==============================] - 0s 174us/step - loss: 0.0207 - val_loss: 0.0395\n",
      "Epoch 686/1000\n",
      "158/158 [==============================] - 0s 170us/step - loss: 0.0207 - val_loss: 0.0395\n",
      "Epoch 687/1000\n",
      "158/158 [==============================] - 0s 141us/step - loss: 0.0207 - val_loss: 0.0394\n",
      "Epoch 688/1000\n",
      "158/158 [==============================] - 0s 173us/step - loss: 0.0206 - val_loss: 0.0394\n",
      "Epoch 689/1000\n",
      "158/158 [==============================] - 0s 157us/step - loss: 0.0206 - val_loss: 0.0393\n",
      "Epoch 690/1000\n",
      "158/158 [==============================] - 0s 183us/step - loss: 0.0206 - val_loss: 0.0393\n",
      "Epoch 691/1000\n",
      "158/158 [==============================] - 0s 139us/step - loss: 0.0205 - val_loss: 0.0393\n",
      "Epoch 692/1000\n",
      "158/158 [==============================] - 0s 138us/step - loss: 0.0205 - val_loss: 0.0392\n",
      "Epoch 693/1000\n",
      "158/158 [==============================] - 0s 146us/step - loss: 0.0205 - val_loss: 0.0392\n",
      "Epoch 694/1000\n",
      "158/158 [==============================] - 0s 160us/step - loss: 0.0204 - val_loss: 0.0391\n",
      "Epoch 695/1000\n",
      "158/158 [==============================] - 0s 137us/step - loss: 0.0204 - val_loss: 0.0391\n",
      "Epoch 696/1000\n",
      "158/158 [==============================] - 0s 122us/step - loss: 0.0204 - val_loss: 0.0391\n",
      "Epoch 697/1000\n",
      "158/158 [==============================] - 0s 128us/step - loss: 0.0203 - val_loss: 0.0390\n",
      "Epoch 698/1000\n",
      "158/158 [==============================] - 0s 114us/step - loss: 0.0203 - val_loss: 0.0390\n",
      "Epoch 699/1000\n",
      "158/158 [==============================] - 0s 131us/step - loss: 0.0203 - val_loss: 0.0390\n",
      "Epoch 700/1000\n",
      "158/158 [==============================] - 0s 159us/step - loss: 0.0202 - val_loss: 0.0389\n",
      "Epoch 701/1000\n",
      "158/158 [==============================] - 0s 197us/step - loss: 0.0202 - val_loss: 0.0389\n",
      "Epoch 702/1000\n",
      "158/158 [==============================] - 0s 181us/step - loss: 0.0202 - val_loss: 0.0388\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 703/1000\n",
      "158/158 [==============================] - 0s 150us/step - loss: 0.0201 - val_loss: 0.0388\n",
      "Epoch 704/1000\n",
      "158/158 [==============================] - 0s 136us/step - loss: 0.0201 - val_loss: 0.0388\n",
      "Epoch 705/1000\n",
      "158/158 [==============================] - 0s 196us/step - loss: 0.0201 - val_loss: 0.0387\n",
      "Epoch 706/1000\n",
      "158/158 [==============================] - 0s 147us/step - loss: 0.0200 - val_loss: 0.0387\n",
      "Epoch 707/1000\n",
      "158/158 [==============================] - 0s 150us/step - loss: 0.0200 - val_loss: 0.0387\n",
      "Epoch 708/1000\n",
      "158/158 [==============================] - 0s 150us/step - loss: 0.0200 - val_loss: 0.0386\n",
      "Epoch 709/1000\n",
      "158/158 [==============================] - 0s 168us/step - loss: 0.0199 - val_loss: 0.0386\n",
      "Epoch 710/1000\n",
      "158/158 [==============================] - 0s 136us/step - loss: 0.0199 - val_loss: 0.0385\n",
      "Epoch 711/1000\n",
      "158/158 [==============================] - 0s 197us/step - loss: 0.0199 - val_loss: 0.0385\n",
      "Epoch 712/1000\n",
      "158/158 [==============================] - 0s 160us/step - loss: 0.0199 - val_loss: 0.0385\n",
      "Epoch 713/1000\n",
      "158/158 [==============================] - 0s 153us/step - loss: 0.0198 - val_loss: 0.0384\n",
      "Epoch 714/1000\n",
      "158/158 [==============================] - 0s 176us/step - loss: 0.0198 - val_loss: 0.0384\n",
      "Epoch 715/1000\n",
      "158/158 [==============================] - 0s 172us/step - loss: 0.0198 - val_loss: 0.0384\n",
      "Epoch 716/1000\n",
      "158/158 [==============================] - 0s 178us/step - loss: 0.0197 - val_loss: 0.0383\n",
      "Epoch 717/1000\n",
      "158/158 [==============================] - 0s 158us/step - loss: 0.0197 - val_loss: 0.0383\n",
      "Epoch 718/1000\n",
      "158/158 [==============================] - 0s 145us/step - loss: 0.0197 - val_loss: 0.0383\n",
      "Epoch 719/1000\n",
      "158/158 [==============================] - 0s 146us/step - loss: 0.0196 - val_loss: 0.0382\n",
      "Epoch 720/1000\n",
      "158/158 [==============================] - 0s 133us/step - loss: 0.0196 - val_loss: 0.0382\n",
      "Epoch 721/1000\n",
      "158/158 [==============================] - 0s 178us/step - loss: 0.0196 - val_loss: 0.0381\n",
      "Epoch 722/1000\n",
      "158/158 [==============================] - 0s 151us/step - loss: 0.0196 - val_loss: 0.0381\n",
      "Epoch 723/1000\n",
      "158/158 [==============================] - 0s 168us/step - loss: 0.0195 - val_loss: 0.0381\n",
      "Epoch 724/1000\n",
      "158/158 [==============================] - 0s 160us/step - loss: 0.0195 - val_loss: 0.0380\n",
      "Epoch 725/1000\n",
      "158/158 [==============================] - 0s 152us/step - loss: 0.0195 - val_loss: 0.0380\n",
      "Epoch 726/1000\n",
      "158/158 [==============================] - 0s 130us/step - loss: 0.0194 - val_loss: 0.0380\n",
      "Epoch 727/1000\n",
      "158/158 [==============================] - 0s 141us/step - loss: 0.0194 - val_loss: 0.0379\n",
      "Epoch 728/1000\n",
      "158/158 [==============================] - 0s 140us/step - loss: 0.0194 - val_loss: 0.0379\n",
      "Epoch 729/1000\n",
      "158/158 [==============================] - 0s 137us/step - loss: 0.0194 - val_loss: 0.0379\n",
      "Epoch 730/1000\n",
      "158/158 [==============================] - 0s 147us/step - loss: 0.0193 - val_loss: 0.0378\n",
      "Epoch 731/1000\n",
      "158/158 [==============================] - 0s 150us/step - loss: 0.0193 - val_loss: 0.0378\n",
      "Epoch 732/1000\n",
      "158/158 [==============================] - 0s 178us/step - loss: 0.0193 - val_loss: 0.0377\n",
      "Epoch 733/1000\n",
      "158/158 [==============================] - 0s 170us/step - loss: 0.0192 - val_loss: 0.0377\n",
      "Epoch 734/1000\n",
      "158/158 [==============================] - 0s 198us/step - loss: 0.0192 - val_loss: 0.0377\n",
      "Epoch 735/1000\n",
      "158/158 [==============================] - 0s 174us/step - loss: 0.0192 - val_loss: 0.0376\n",
      "Epoch 736/1000\n",
      "158/158 [==============================] - 0s 158us/step - loss: 0.0192 - val_loss: 0.0376\n",
      "Epoch 737/1000\n",
      "158/158 [==============================] - 0s 133us/step - loss: 0.0191 - val_loss: 0.0376\n",
      "Epoch 738/1000\n",
      "158/158 [==============================] - 0s 144us/step - loss: 0.0191 - val_loss: 0.0375\n",
      "Epoch 739/1000\n",
      "158/158 [==============================] - 0s 168us/step - loss: 0.0191 - val_loss: 0.0375\n",
      "Epoch 740/1000\n",
      "158/158 [==============================] - 0s 178us/step - loss: 0.0190 - val_loss: 0.0375\n",
      "Epoch 741/1000\n",
      "158/158 [==============================] - 0s 158us/step - loss: 0.0190 - val_loss: 0.0374\n",
      "Epoch 742/1000\n",
      "158/158 [==============================] - 0s 165us/step - loss: 0.0190 - val_loss: 0.0374\n",
      "Epoch 743/1000\n",
      "158/158 [==============================] - 0s 237us/step - loss: 0.0190 - val_loss: 0.0373\n",
      "Epoch 744/1000\n",
      "158/158 [==============================] - 0s 177us/step - loss: 0.0189 - val_loss: 0.0373\n",
      "Epoch 745/1000\n",
      "158/158 [==============================] - 0s 183us/step - loss: 0.0189 - val_loss: 0.0373\n",
      "Epoch 746/1000\n",
      "158/158 [==============================] - 0s 139us/step - loss: 0.0189 - val_loss: 0.0372\n",
      "Epoch 747/1000\n",
      "158/158 [==============================] - 0s 133us/step - loss: 0.0189 - val_loss: 0.0372\n",
      "Epoch 748/1000\n",
      "158/158 [==============================] - 0s 136us/step - loss: 0.0188 - val_loss: 0.0372\n",
      "Epoch 749/1000\n",
      "158/158 [==============================] - 0s 178us/step - loss: 0.0188 - val_loss: 0.0371\n",
      "Epoch 750/1000\n",
      "158/158 [==============================] - 0s 142us/step - loss: 0.0188 - val_loss: 0.0371\n",
      "Epoch 751/1000\n",
      "158/158 [==============================] - 0s 132us/step - loss: 0.0188 - val_loss: 0.0371\n",
      "Epoch 752/1000\n",
      "158/158 [==============================] - 0s 127us/step - loss: 0.0187 - val_loss: 0.0370\n",
      "Epoch 753/1000\n",
      "158/158 [==============================] - 0s 142us/step - loss: 0.0187 - val_loss: 0.0370\n",
      "Epoch 754/1000\n",
      "158/158 [==============================] - 0s 178us/step - loss: 0.0187 - val_loss: 0.0370\n",
      "Epoch 755/1000\n",
      "158/158 [==============================] - 0s 181us/step - loss: 0.0186 - val_loss: 0.0369\n",
      "Epoch 756/1000\n",
      "158/158 [==============================] - 0s 172us/step - loss: 0.0186 - val_loss: 0.0369\n",
      "Epoch 757/1000\n",
      "158/158 [==============================] - 0s 125us/step - loss: 0.0186 - val_loss: 0.0369\n",
      "Epoch 758/1000\n",
      "158/158 [==============================] - 0s 128us/step - loss: 0.0186 - val_loss: 0.0368\n",
      "Epoch 759/1000\n",
      "158/158 [==============================] - 0s 114us/step - loss: 0.0185 - val_loss: 0.0368\n",
      "Epoch 760/1000\n",
      "158/158 [==============================] - 0s 176us/step - loss: 0.0185 - val_loss: 0.0367\n",
      "Epoch 761/1000\n",
      "158/158 [==============================] - 0s 143us/step - loss: 0.0185 - val_loss: 0.0367\n",
      "Epoch 762/1000\n",
      "158/158 [==============================] - 0s 161us/step - loss: 0.0185 - val_loss: 0.0367\n",
      "Epoch 763/1000\n",
      "158/158 [==============================] - 0s 156us/step - loss: 0.0184 - val_loss: 0.0366\n",
      "Epoch 764/1000\n",
      "158/158 [==============================] - 0s 170us/step - loss: 0.0184 - val_loss: 0.0366\n",
      "Epoch 765/1000\n",
      "158/158 [==============================] - 0s 174us/step - loss: 0.0184 - val_loss: 0.0366\n",
      "Epoch 766/1000\n",
      "158/158 [==============================] - 0s 155us/step - loss: 0.0184 - val_loss: 0.0365\n",
      "Epoch 767/1000\n",
      "158/158 [==============================] - 0s 127us/step - loss: 0.0183 - val_loss: 0.0365\n",
      "Epoch 768/1000\n",
      "158/158 [==============================] - 0s 153us/step - loss: 0.0183 - val_loss: 0.0365\n",
      "Epoch 769/1000\n",
      "158/158 [==============================] - 0s 159us/step - loss: 0.0183 - val_loss: 0.0364\n",
      "Epoch 770/1000\n",
      "158/158 [==============================] - 0s 159us/step - loss: 0.0183 - val_loss: 0.0364\n",
      "Epoch 771/1000\n",
      "158/158 [==============================] - 0s 162us/step - loss: 0.0183 - val_loss: 0.0364\n",
      "Epoch 772/1000\n",
      "158/158 [==============================] - 0s 136us/step - loss: 0.0182 - val_loss: 0.0363\n",
      "Epoch 773/1000\n",
      "158/158 [==============================] - 0s 119us/step - loss: 0.0182 - val_loss: 0.0363\n",
      "Epoch 774/1000\n",
      "158/158 [==============================] - 0s 143us/step - loss: 0.0182 - val_loss: 0.0363\n",
      "Epoch 775/1000\n",
      "158/158 [==============================] - 0s 128us/step - loss: 0.0182 - val_loss: 0.0362\n",
      "Epoch 776/1000\n",
      "158/158 [==============================] - 0s 132us/step - loss: 0.0181 - val_loss: 0.0362\n",
      "Epoch 777/1000\n",
      "158/158 [==============================] - 0s 171us/step - loss: 0.0181 - val_loss: 0.0362\n",
      "Epoch 778/1000\n",
      "158/158 [==============================] - 0s 176us/step - loss: 0.0181 - val_loss: 0.0361\n",
      "Epoch 779/1000\n",
      "158/158 [==============================] - 0s 155us/step - loss: 0.0181 - val_loss: 0.0361\n",
      "Epoch 780/1000\n",
      "158/158 [==============================] - 0s 177us/step - loss: 0.0180 - val_loss: 0.0360\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 781/1000\n",
      "158/158 [==============================] - 0s 157us/step - loss: 0.0180 - val_loss: 0.0360\n",
      "Epoch 782/1000\n",
      "158/158 [==============================] - 0s 148us/step - loss: 0.0180 - val_loss: 0.0360\n",
      "Epoch 783/1000\n",
      "158/158 [==============================] - 0s 196us/step - loss: 0.0180 - val_loss: 0.0359\n",
      "Epoch 784/1000\n",
      "158/158 [==============================] - 0s 153us/step - loss: 0.0179 - val_loss: 0.0359\n",
      "Epoch 785/1000\n",
      "158/158 [==============================] - 0s 141us/step - loss: 0.0179 - val_loss: 0.0359\n",
      "Epoch 786/1000\n",
      "158/158 [==============================] - 0s 131us/step - loss: 0.0179 - val_loss: 0.0358\n",
      "Epoch 787/1000\n",
      "158/158 [==============================] - 0s 128us/step - loss: 0.0179 - val_loss: 0.0358\n",
      "Epoch 788/1000\n",
      "158/158 [==============================] - 0s 190us/step - loss: 0.0179 - val_loss: 0.0358\n",
      "Epoch 789/1000\n",
      "158/158 [==============================] - 0s 237us/step - loss: 0.0178 - val_loss: 0.0357\n",
      "Epoch 790/1000\n",
      "158/158 [==============================] - 0s 168us/step - loss: 0.0178 - val_loss: 0.0357\n",
      "Epoch 791/1000\n",
      "158/158 [==============================] - 0s 175us/step - loss: 0.0178 - val_loss: 0.0357\n",
      "Epoch 792/1000\n",
      "158/158 [==============================] - 0s 131us/step - loss: 0.0178 - val_loss: 0.0356\n",
      "Epoch 793/1000\n",
      "158/158 [==============================] - 0s 180us/step - loss: 0.0177 - val_loss: 0.0356\n",
      "Epoch 794/1000\n",
      "158/158 [==============================] - 0s 149us/step - loss: 0.0177 - val_loss: 0.0356\n",
      "Epoch 795/1000\n",
      "158/158 [==============================] - 0s 122us/step - loss: 0.0177 - val_loss: 0.0355\n",
      "Epoch 796/1000\n",
      "158/158 [==============================] - 0s 137us/step - loss: 0.0177 - val_loss: 0.0355\n",
      "Epoch 797/1000\n",
      "158/158 [==============================] - 0s 139us/step - loss: 0.0176 - val_loss: 0.0355\n",
      "Epoch 798/1000\n",
      "158/158 [==============================] - 0s 152us/step - loss: 0.0176 - val_loss: 0.0354\n",
      "Epoch 799/1000\n",
      "158/158 [==============================] - 0s 183us/step - loss: 0.0176 - val_loss: 0.0354\n",
      "Epoch 800/1000\n",
      "158/158 [==============================] - 0s 167us/step - loss: 0.0176 - val_loss: 0.0354\n",
      "Epoch 801/1000\n",
      "158/158 [==============================] - 0s 115us/step - loss: 0.0176 - val_loss: 0.0353\n",
      "Epoch 802/1000\n",
      "158/158 [==============================] - 0s 137us/step - loss: 0.0175 - val_loss: 0.0353\n",
      "Epoch 803/1000\n",
      "158/158 [==============================] - 0s 144us/step - loss: 0.0175 - val_loss: 0.0353\n",
      "Epoch 804/1000\n",
      "158/158 [==============================] - 0s 155us/step - loss: 0.0175 - val_loss: 0.0352\n",
      "Epoch 805/1000\n",
      "158/158 [==============================] - 0s 159us/step - loss: 0.0175 - val_loss: 0.0352\n",
      "Epoch 806/1000\n",
      "158/158 [==============================] - 0s 126us/step - loss: 0.0175 - val_loss: 0.0352\n",
      "Epoch 807/1000\n",
      "158/158 [==============================] - 0s 140us/step - loss: 0.0174 - val_loss: 0.0351\n",
      "Epoch 808/1000\n",
      "158/158 [==============================] - 0s 147us/step - loss: 0.0174 - val_loss: 0.0351\n",
      "Epoch 809/1000\n",
      "158/158 [==============================] - 0s 150us/step - loss: 0.0174 - val_loss: 0.0351\n",
      "Epoch 810/1000\n",
      "158/158 [==============================] - 0s 156us/step - loss: 0.0174 - val_loss: 0.0350\n",
      "Epoch 811/1000\n",
      "158/158 [==============================] - 0s 156us/step - loss: 0.0173 - val_loss: 0.0350\n",
      "Epoch 812/1000\n",
      "158/158 [==============================] - 0s 183us/step - loss: 0.0173 - val_loss: 0.0349\n",
      "Epoch 813/1000\n",
      "158/158 [==============================] - 0s 140us/step - loss: 0.0173 - val_loss: 0.0349\n",
      "Epoch 814/1000\n",
      "158/158 [==============================] - 0s 135us/step - loss: 0.0173 - val_loss: 0.0349\n",
      "Epoch 815/1000\n",
      "158/158 [==============================] - 0s 127us/step - loss: 0.0173 - val_loss: 0.0348\n",
      "Epoch 816/1000\n",
      "158/158 [==============================] - 0s 115us/step - loss: 0.0172 - val_loss: 0.0348\n",
      "Epoch 817/1000\n",
      "158/158 [==============================] - 0s 188us/step - loss: 0.0172 - val_loss: 0.0348\n",
      "Epoch 818/1000\n",
      "158/158 [==============================] - 0s 174us/step - loss: 0.0172 - val_loss: 0.0347\n",
      "Epoch 819/1000\n",
      "158/158 [==============================] - 0s 126us/step - loss: 0.0172 - val_loss: 0.0347\n",
      "Epoch 820/1000\n",
      "158/158 [==============================] - 0s 164us/step - loss: 0.0172 - val_loss: 0.0347\n",
      "Epoch 821/1000\n",
      "158/158 [==============================] - 0s 178us/step - loss: 0.0171 - val_loss: 0.0346\n",
      "Epoch 822/1000\n",
      "158/158 [==============================] - 0s 210us/step - loss: 0.0171 - val_loss: 0.0346\n",
      "Epoch 823/1000\n",
      "158/158 [==============================] - 0s 150us/step - loss: 0.0171 - val_loss: 0.0346\n",
      "Epoch 824/1000\n",
      "158/158 [==============================] - 0s 121us/step - loss: 0.0171 - val_loss: 0.0345\n",
      "Epoch 825/1000\n",
      "158/158 [==============================] - 0s 167us/step - loss: 0.0171 - val_loss: 0.0345\n",
      "Epoch 826/1000\n",
      "158/158 [==============================] - 0s 193us/step - loss: 0.0170 - val_loss: 0.0345\n",
      "Epoch 827/1000\n",
      "158/158 [==============================] - 0s 157us/step - loss: 0.0170 - val_loss: 0.0344\n",
      "Epoch 828/1000\n",
      "158/158 [==============================] - 0s 146us/step - loss: 0.0170 - val_loss: 0.0344\n",
      "Epoch 829/1000\n",
      "158/158 [==============================] - 0s 146us/step - loss: 0.0170 - val_loss: 0.0344\n",
      "Epoch 830/1000\n",
      "158/158 [==============================] - 0s 172us/step - loss: 0.0170 - val_loss: 0.0343\n",
      "Epoch 831/1000\n",
      "158/158 [==============================] - 0s 205us/step - loss: 0.0169 - val_loss: 0.0343\n",
      "Epoch 832/1000\n",
      "158/158 [==============================] - 0s 153us/step - loss: 0.0169 - val_loss: 0.0343\n",
      "Epoch 833/1000\n",
      "158/158 [==============================] - 0s 166us/step - loss: 0.0169 - val_loss: 0.0342\n",
      "Epoch 834/1000\n",
      "158/158 [==============================] - 0s 142us/step - loss: 0.0169 - val_loss: 0.0342\n",
      "Epoch 835/1000\n",
      "158/158 [==============================] - 0s 131us/step - loss: 0.0169 - val_loss: 0.0342\n",
      "Epoch 836/1000\n",
      "158/158 [==============================] - 0s 183us/step - loss: 0.0168 - val_loss: 0.0341\n",
      "Epoch 837/1000\n",
      "158/158 [==============================] - 0s 171us/step - loss: 0.0168 - val_loss: 0.0341\n",
      "Epoch 838/1000\n",
      "158/158 [==============================] - 0s 150us/step - loss: 0.0168 - val_loss: 0.0341\n",
      "Epoch 839/1000\n",
      "158/158 [==============================] - 0s 152us/step - loss: 0.0168 - val_loss: 0.0340\n",
      "Epoch 840/1000\n",
      "158/158 [==============================] - 0s 153us/step - loss: 0.0168 - val_loss: 0.0340\n",
      "Epoch 841/1000\n",
      "158/158 [==============================] - 0s 144us/step - loss: 0.0167 - val_loss: 0.0340\n",
      "Epoch 842/1000\n",
      "158/158 [==============================] - 0s 164us/step - loss: 0.0167 - val_loss: 0.0339\n",
      "Epoch 843/1000\n",
      "158/158 [==============================] - 0s 172us/step - loss: 0.0167 - val_loss: 0.0339\n",
      "Epoch 844/1000\n",
      "158/158 [==============================] - 0s 169us/step - loss: 0.0167 - val_loss: 0.0339\n",
      "Epoch 845/1000\n",
      "158/158 [==============================] - 0s 147us/step - loss: 0.0167 - val_loss: 0.0338\n",
      "Epoch 846/1000\n",
      "158/158 [==============================] - 0s 150us/step - loss: 0.0166 - val_loss: 0.0338\n",
      "Epoch 847/1000\n",
      "158/158 [==============================] - 0s 166us/step - loss: 0.0166 - val_loss: 0.0338\n",
      "Epoch 848/1000\n",
      "158/158 [==============================] - 0s 151us/step - loss: 0.0166 - val_loss: 0.0337\n",
      "Epoch 849/1000\n",
      "158/158 [==============================] - 0s 125us/step - loss: 0.0166 - val_loss: 0.0337\n",
      "Epoch 850/1000\n",
      "158/158 [==============================] - 0s 142us/step - loss: 0.0166 - val_loss: 0.0337\n",
      "Epoch 851/1000\n",
      "158/158 [==============================] - 0s 135us/step - loss: 0.0165 - val_loss: 0.0336\n",
      "Epoch 852/1000\n",
      "158/158 [==============================] - 0s 121us/step - loss: 0.0165 - val_loss: 0.0336\n",
      "Epoch 853/1000\n",
      "158/158 [==============================] - 0s 158us/step - loss: 0.0165 - val_loss: 0.0336\n",
      "Epoch 854/1000\n",
      "158/158 [==============================] - 0s 160us/step - loss: 0.0165 - val_loss: 0.0335\n",
      "Epoch 855/1000\n",
      "158/158 [==============================] - 0s 163us/step - loss: 0.0165 - val_loss: 0.0335\n",
      "Epoch 856/1000\n",
      "158/158 [==============================] - 0s 142us/step - loss: 0.0164 - val_loss: 0.0335\n",
      "Epoch 857/1000\n",
      "158/158 [==============================] - 0s 160us/step - loss: 0.0164 - val_loss: 0.0334\n",
      "Epoch 858/1000\n",
      "158/158 [==============================] - 0s 146us/step - loss: 0.0164 - val_loss: 0.0334\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 859/1000\n",
      "158/158 [==============================] - 0s 164us/step - loss: 0.0164 - val_loss: 0.0334\n",
      "Epoch 860/1000\n",
      "158/158 [==============================] - 0s 159us/step - loss: 0.0164 - val_loss: 0.0333\n",
      "Epoch 861/1000\n",
      "158/158 [==============================] - 0s 188us/step - loss: 0.0163 - val_loss: 0.0333\n",
      "Epoch 862/1000\n",
      "158/158 [==============================] - 0s 139us/step - loss: 0.0163 - val_loss: 0.0333\n",
      "Epoch 863/1000\n",
      "158/158 [==============================] - 0s 152us/step - loss: 0.0163 - val_loss: 0.0332\n",
      "Epoch 864/1000\n",
      "158/158 [==============================] - 0s 123us/step - loss: 0.0163 - val_loss: 0.0332\n",
      "Epoch 865/1000\n",
      "158/158 [==============================] - 0s 196us/step - loss: 0.0163 - val_loss: 0.0332\n",
      "Epoch 866/1000\n",
      "158/158 [==============================] - 0s 193us/step - loss: 0.0163 - val_loss: 0.0331\n",
      "Epoch 867/1000\n",
      "158/158 [==============================] - 0s 143us/step - loss: 0.0162 - val_loss: 0.0331\n",
      "Epoch 868/1000\n",
      "158/158 [==============================] - 0s 158us/step - loss: 0.0162 - val_loss: 0.0331\n",
      "Epoch 869/1000\n",
      "158/158 [==============================] - 0s 156us/step - loss: 0.0162 - val_loss: 0.0330\n",
      "Epoch 870/1000\n",
      "158/158 [==============================] - 0s 153us/step - loss: 0.0162 - val_loss: 0.0330\n",
      "Epoch 871/1000\n",
      "158/158 [==============================] - 0s 154us/step - loss: 0.0162 - val_loss: 0.0330\n",
      "Epoch 872/1000\n",
      "158/158 [==============================] - 0s 168us/step - loss: 0.0161 - val_loss: 0.0329\n",
      "Epoch 873/1000\n",
      "158/158 [==============================] - 0s 169us/step - loss: 0.0161 - val_loss: 0.0329\n",
      "Epoch 874/1000\n",
      "158/158 [==============================] - 0s 123us/step - loss: 0.0161 - val_loss: 0.0329\n",
      "Epoch 875/1000\n",
      "158/158 [==============================] - 0s 165us/step - loss: 0.0161 - val_loss: 0.0328\n",
      "Epoch 876/1000\n",
      "158/158 [==============================] - 0s 149us/step - loss: 0.0161 - val_loss: 0.0328\n",
      "Epoch 877/1000\n",
      "158/158 [==============================] - 0s 148us/step - loss: 0.0161 - val_loss: 0.0328\n",
      "Epoch 878/1000\n",
      "158/158 [==============================] - 0s 154us/step - loss: 0.0160 - val_loss: 0.0327\n",
      "Epoch 879/1000\n",
      "158/158 [==============================] - 0s 127us/step - loss: 0.0160 - val_loss: 0.0327\n",
      "Epoch 880/1000\n",
      "158/158 [==============================] - 0s 143us/step - loss: 0.0160 - val_loss: 0.0327\n",
      "Epoch 881/1000\n",
      "158/158 [==============================] - 0s 120us/step - loss: 0.0160 - val_loss: 0.0326\n",
      "Epoch 882/1000\n",
      "158/158 [==============================] - 0s 152us/step - loss: 0.0160 - val_loss: 0.0326\n",
      "Epoch 883/1000\n",
      "158/158 [==============================] - 0s 132us/step - loss: 0.0159 - val_loss: 0.0326\n",
      "Epoch 884/1000\n",
      "158/158 [==============================] - 0s 157us/step - loss: 0.0159 - val_loss: 0.0325\n",
      "Epoch 885/1000\n",
      "158/158 [==============================] - 0s 143us/step - loss: 0.0159 - val_loss: 0.0325\n",
      "Epoch 886/1000\n",
      "158/158 [==============================] - 0s 140us/step - loss: 0.0159 - val_loss: 0.0325\n",
      "Epoch 887/1000\n",
      "158/158 [==============================] - 0s 145us/step - loss: 0.0159 - val_loss: 0.0324\n",
      "Epoch 888/1000\n",
      "158/158 [==============================] - 0s 164us/step - loss: 0.0159 - val_loss: 0.0324\n",
      "Epoch 889/1000\n",
      "158/158 [==============================] - 0s 188us/step - loss: 0.0158 - val_loss: 0.0324\n",
      "Epoch 890/1000\n",
      "158/158 [==============================] - 0s 149us/step - loss: 0.0158 - val_loss: 0.0323\n",
      "Epoch 891/1000\n",
      "158/158 [==============================] - 0s 174us/step - loss: 0.0158 - val_loss: 0.0323\n",
      "Epoch 892/1000\n",
      "158/158 [==============================] - 0s 130us/step - loss: 0.0158 - val_loss: 0.0323\n",
      "Epoch 893/1000\n",
      "158/158 [==============================] - 0s 138us/step - loss: 0.0158 - val_loss: 0.0322\n",
      "Epoch 894/1000\n",
      "158/158 [==============================] - 0s 149us/step - loss: 0.0157 - val_loss: 0.0322\n",
      "Epoch 895/1000\n",
      "158/158 [==============================] - 0s 164us/step - loss: 0.0157 - val_loss: 0.0322\n",
      "Epoch 896/1000\n",
      "158/158 [==============================] - 0s 183us/step - loss: 0.0157 - val_loss: 0.0321\n",
      "Epoch 897/1000\n",
      "158/158 [==============================] - 0s 171us/step - loss: 0.0157 - val_loss: 0.0321\n",
      "Epoch 898/1000\n",
      "158/158 [==============================] - 0s 128us/step - loss: 0.0157 - val_loss: 0.0321\n",
      "Epoch 899/1000\n",
      "158/158 [==============================] - 0s 121us/step - loss: 0.0157 - val_loss: 0.0320\n",
      "Epoch 900/1000\n",
      "158/158 [==============================] - 0s 237us/step - loss: 0.0156 - val_loss: 0.0320\n",
      "Epoch 901/1000\n",
      "158/158 [==============================] - 0s 178us/step - loss: 0.0156 - val_loss: 0.0320\n",
      "Epoch 902/1000\n",
      "158/158 [==============================] - 0s 188us/step - loss: 0.0156 - val_loss: 0.0319\n",
      "Epoch 903/1000\n",
      "158/158 [==============================] - 0s 150us/step - loss: 0.0156 - val_loss: 0.0319\n",
      "Epoch 904/1000\n",
      "158/158 [==============================] - 0s 157us/step - loss: 0.0156 - val_loss: 0.0319\n",
      "Epoch 905/1000\n",
      "158/158 [==============================] - 0s 130us/step - loss: 0.0156 - val_loss: 0.0318\n",
      "Epoch 906/1000\n",
      "158/158 [==============================] - 0s 144us/step - loss: 0.0155 - val_loss: 0.0318\n",
      "Epoch 907/1000\n",
      "158/158 [==============================] - 0s 150us/step - loss: 0.0155 - val_loss: 0.0318\n",
      "Epoch 908/1000\n",
      "158/158 [==============================] - 0s 159us/step - loss: 0.0155 - val_loss: 0.0317\n",
      "Epoch 909/1000\n",
      "158/158 [==============================] - 0s 184us/step - loss: 0.0155 - val_loss: 0.0317\n",
      "Epoch 910/1000\n",
      "158/158 [==============================] - 0s 127us/step - loss: 0.0155 - val_loss: 0.0317\n",
      "Epoch 911/1000\n",
      "158/158 [==============================] - 0s 123us/step - loss: 0.0155 - val_loss: 0.0316\n",
      "Epoch 912/1000\n",
      "158/158 [==============================] - 0s 193us/step - loss: 0.0154 - val_loss: 0.0316\n",
      "Epoch 913/1000\n",
      "158/158 [==============================] - 0s 166us/step - loss: 0.0154 - val_loss: 0.0316\n",
      "Epoch 914/1000\n",
      "158/158 [==============================] - 0s 151us/step - loss: 0.0154 - val_loss: 0.0315\n",
      "Epoch 915/1000\n",
      "158/158 [==============================] - 0s 137us/step - loss: 0.0154 - val_loss: 0.0315\n",
      "Epoch 916/1000\n",
      "158/158 [==============================] - 0s 157us/step - loss: 0.0154 - val_loss: 0.0315\n",
      "Epoch 917/1000\n",
      "158/158 [==============================] - 0s 155us/step - loss: 0.0153 - val_loss: 0.0315\n",
      "Epoch 918/1000\n",
      "158/158 [==============================] - 0s 128us/step - loss: 0.0153 - val_loss: 0.0314\n",
      "Epoch 919/1000\n",
      "158/158 [==============================] - 0s 128us/step - loss: 0.0153 - val_loss: 0.0314\n",
      "Epoch 920/1000\n",
      "158/158 [==============================] - 0s 153us/step - loss: 0.0153 - val_loss: 0.0314\n",
      "Epoch 921/1000\n",
      "158/158 [==============================] - 0s 128us/step - loss: 0.0153 - val_loss: 0.0313\n",
      "Epoch 922/1000\n",
      "158/158 [==============================] - 0s 149us/step - loss: 0.0153 - val_loss: 0.0313\n",
      "Epoch 923/1000\n",
      "158/158 [==============================] - 0s 170us/step - loss: 0.0152 - val_loss: 0.0313\n",
      "Epoch 924/1000\n",
      "158/158 [==============================] - 0s 157us/step - loss: 0.0152 - val_loss: 0.0312\n",
      "Epoch 925/1000\n",
      "158/158 [==============================] - 0s 165us/step - loss: 0.0152 - val_loss: 0.0312\n",
      "Epoch 926/1000\n",
      "158/158 [==============================] - 0s 180us/step - loss: 0.0152 - val_loss: 0.0312\n",
      "Epoch 927/1000\n",
      "158/158 [==============================] - 0s 182us/step - loss: 0.0152 - val_loss: 0.0311\n",
      "Epoch 928/1000\n",
      "158/158 [==============================] - 0s 151us/step - loss: 0.0152 - val_loss: 0.0311\n",
      "Epoch 929/1000\n",
      "158/158 [==============================] - 0s 128us/step - loss: 0.0151 - val_loss: 0.0311\n",
      "Epoch 930/1000\n",
      "158/158 [==============================] - 0s 146us/step - loss: 0.0151 - val_loss: 0.0310\n",
      "Epoch 931/1000\n",
      "158/158 [==============================] - 0s 181us/step - loss: 0.0151 - val_loss: 0.0310\n",
      "Epoch 932/1000\n",
      "158/158 [==============================] - 0s 139us/step - loss: 0.0151 - val_loss: 0.0310\n",
      "Epoch 933/1000\n",
      "158/158 [==============================] - 0s 164us/step - loss: 0.0151 - val_loss: 0.0309\n",
      "Epoch 934/1000\n",
      "158/158 [==============================] - 0s 162us/step - loss: 0.0151 - val_loss: 0.0309\n",
      "Epoch 935/1000\n",
      "158/158 [==============================] - 0s 152us/step - loss: 0.0150 - val_loss: 0.0309\n",
      "Epoch 936/1000\n",
      "158/158 [==============================] - 0s 176us/step - loss: 0.0150 - val_loss: 0.0308\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 937/1000\n",
      "158/158 [==============================] - 0s 142us/step - loss: 0.0150 - val_loss: 0.0308\n",
      "Epoch 938/1000\n",
      "158/158 [==============================] - 0s 192us/step - loss: 0.0150 - val_loss: 0.0308\n",
      "Epoch 939/1000\n",
      "158/158 [==============================] - 0s 187us/step - loss: 0.0150 - val_loss: 0.0308\n",
      "Epoch 940/1000\n",
      "158/158 [==============================] - 0s 143us/step - loss: 0.0150 - val_loss: 0.0307\n",
      "Epoch 941/1000\n",
      "158/158 [==============================] - 0s 144us/step - loss: 0.0149 - val_loss: 0.0307\n",
      "Epoch 942/1000\n",
      "158/158 [==============================] - 0s 141us/step - loss: 0.0149 - val_loss: 0.0307\n",
      "Epoch 943/1000\n",
      "158/158 [==============================] - 0s 145us/step - loss: 0.0149 - val_loss: 0.0306\n",
      "Epoch 944/1000\n",
      "158/158 [==============================] - 0s 156us/step - loss: 0.0149 - val_loss: 0.0306\n",
      "Epoch 945/1000\n",
      "158/158 [==============================] - 0s 167us/step - loss: 0.0149 - val_loss: 0.0306\n",
      "Epoch 946/1000\n",
      "158/158 [==============================] - 0s 141us/step - loss: 0.0149 - val_loss: 0.0305\n",
      "Epoch 947/1000\n",
      "158/158 [==============================] - 0s 184us/step - loss: 0.0149 - val_loss: 0.0305\n",
      "Epoch 948/1000\n",
      "158/158 [==============================] - 0s 171us/step - loss: 0.0148 - val_loss: 0.0305\n",
      "Epoch 949/1000\n",
      "158/158 [==============================] - 0s 172us/step - loss: 0.0148 - val_loss: 0.0304\n",
      "Epoch 950/1000\n",
      "158/158 [==============================] - 0s 144us/step - loss: 0.0148 - val_loss: 0.0304\n",
      "Epoch 951/1000\n",
      "158/158 [==============================] - 0s 161us/step - loss: 0.0148 - val_loss: 0.0304\n",
      "Epoch 952/1000\n",
      "158/158 [==============================] - 0s 150us/step - loss: 0.0148 - val_loss: 0.0303\n",
      "Epoch 953/1000\n",
      "158/158 [==============================] - 0s 173us/step - loss: 0.0148 - val_loss: 0.0303\n",
      "Epoch 954/1000\n",
      "158/158 [==============================] - 0s 143us/step - loss: 0.0147 - val_loss: 0.0303\n",
      "Epoch 955/1000\n",
      "158/158 [==============================] - 0s 158us/step - loss: 0.0147 - val_loss: 0.0303\n",
      "Epoch 956/1000\n",
      "158/158 [==============================] - 0s 157us/step - loss: 0.0147 - val_loss: 0.0302\n",
      "Epoch 957/1000\n",
      "158/158 [==============================] - 0s 156us/step - loss: 0.0147 - val_loss: 0.0302\n",
      "Epoch 958/1000\n",
      "158/158 [==============================] - 0s 176us/step - loss: 0.0147 - val_loss: 0.0302\n",
      "Epoch 959/1000\n",
      "158/158 [==============================] - 0s 233us/step - loss: 0.0147 - val_loss: 0.0301\n",
      "Epoch 960/1000\n",
      "158/158 [==============================] - 0s 150us/step - loss: 0.0146 - val_loss: 0.0301\n",
      "Epoch 961/1000\n",
      "158/158 [==============================] - 0s 175us/step - loss: 0.0146 - val_loss: 0.0301\n",
      "Epoch 962/1000\n",
      "158/158 [==============================] - 0s 137us/step - loss: 0.0146 - val_loss: 0.0300\n",
      "Epoch 963/1000\n",
      "158/158 [==============================] - 0s 285us/step - loss: 0.0146 - val_loss: 0.0300\n",
      "Epoch 964/1000\n",
      "158/158 [==============================] - 0s 165us/step - loss: 0.0146 - val_loss: 0.0300\n",
      "Epoch 965/1000\n",
      "158/158 [==============================] - 0s 210us/step - loss: 0.0146 - val_loss: 0.0299\n",
      "Epoch 966/1000\n",
      "158/158 [==============================] - 0s 193us/step - loss: 0.0145 - val_loss: 0.0299\n",
      "Epoch 967/1000\n",
      "158/158 [==============================] - 0s 165us/step - loss: 0.0145 - val_loss: 0.0299\n",
      "Epoch 968/1000\n",
      "158/158 [==============================] - 0s 149us/step - loss: 0.0145 - val_loss: 0.0299\n",
      "Epoch 969/1000\n",
      "158/158 [==============================] - 0s 130us/step - loss: 0.0145 - val_loss: 0.0298\n",
      "Epoch 970/1000\n",
      "158/158 [==============================] - 0s 149us/step - loss: 0.0145 - val_loss: 0.0298\n",
      "Epoch 971/1000\n",
      "158/158 [==============================] - 0s 225us/step - loss: 0.0145 - val_loss: 0.0298\n",
      "Epoch 972/1000\n",
      "158/158 [==============================] - 0s 179us/step - loss: 0.0145 - val_loss: 0.0297\n",
      "Epoch 973/1000\n",
      "158/158 [==============================] - 0s 125us/step - loss: 0.0144 - val_loss: 0.0297\n",
      "Epoch 974/1000\n",
      "158/158 [==============================] - 0s 130us/step - loss: 0.0144 - val_loss: 0.0297\n",
      "Epoch 975/1000\n",
      "158/158 [==============================] - 0s 196us/step - loss: 0.0144 - val_loss: 0.0296\n",
      "Epoch 976/1000\n",
      "158/158 [==============================] - 0s 233us/step - loss: 0.0144 - val_loss: 0.0296\n",
      "Epoch 977/1000\n",
      "158/158 [==============================] - 0s 151us/step - loss: 0.0144 - val_loss: 0.0296\n",
      "Epoch 978/1000\n",
      "158/158 [==============================] - 0s 132us/step - loss: 0.0144 - val_loss: 0.0295\n",
      "Epoch 979/1000\n",
      "158/158 [==============================] - 0s 200us/step - loss: 0.0143 - val_loss: 0.0295\n",
      "Epoch 980/1000\n",
      "158/158 [==============================] - 0s 226us/step - loss: 0.0143 - val_loss: 0.0295\n",
      "Epoch 981/1000\n",
      "158/158 [==============================] - 0s 176us/step - loss: 0.0143 - val_loss: 0.0295\n",
      "Epoch 982/1000\n",
      "158/158 [==============================] - 0s 152us/step - loss: 0.0143 - val_loss: 0.0294\n",
      "Epoch 983/1000\n",
      "158/158 [==============================] - 0s 161us/step - loss: 0.0143 - val_loss: 0.0294\n",
      "Epoch 984/1000\n",
      "158/158 [==============================] - 0s 155us/step - loss: 0.0143 - val_loss: 0.0294\n",
      "Epoch 985/1000\n",
      "158/158 [==============================] - 0s 189us/step - loss: 0.0143 - val_loss: 0.0293\n",
      "Epoch 986/1000\n",
      "158/158 [==============================] - 0s 121us/step - loss: 0.0142 - val_loss: 0.0293\n",
      "Epoch 987/1000\n",
      "158/158 [==============================] - 0s 138us/step - loss: 0.0142 - val_loss: 0.0293\n",
      "Epoch 988/1000\n",
      "158/158 [==============================] - 0s 160us/step - loss: 0.0142 - val_loss: 0.0292\n",
      "Epoch 989/1000\n",
      "158/158 [==============================] - 0s 147us/step - loss: 0.0142 - val_loss: 0.0292\n",
      "Epoch 990/1000\n",
      "158/158 [==============================] - 0s 178us/step - loss: 0.0142 - val_loss: 0.0292\n",
      "Epoch 991/1000\n",
      "158/158 [==============================] - 0s 149us/step - loss: 0.0142 - val_loss: 0.0292\n",
      "Epoch 992/1000\n",
      "158/158 [==============================] - 0s 130us/step - loss: 0.0141 - val_loss: 0.0291\n",
      "Epoch 993/1000\n",
      "158/158 [==============================] - 0s 132us/step - loss: 0.0141 - val_loss: 0.0291\n",
      "Epoch 994/1000\n",
      "158/158 [==============================] - 0s 108us/step - loss: 0.0141 - val_loss: 0.0291\n",
      "Epoch 995/1000\n",
      "158/158 [==============================] - 0s 107us/step - loss: 0.0141 - val_loss: 0.0290\n",
      "Epoch 996/1000\n",
      "158/158 [==============================] - 0s 122us/step - loss: 0.0141 - val_loss: 0.0290\n",
      "Epoch 997/1000\n",
      "158/158 [==============================] - 0s 97us/step - loss: 0.0141 - val_loss: 0.0290\n",
      "Epoch 998/1000\n",
      "158/158 [==============================] - 0s 109us/step - loss: 0.0141 - val_loss: 0.0289\n",
      "Epoch 999/1000\n",
      "158/158 [==============================] - 0s 108us/step - loss: 0.0140 - val_loss: 0.0289\n",
      "Epoch 1000/1000\n",
      "158/158 [==============================] - 0s 86us/step - loss: 0.0140 - val_loss: 0.0289\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fa197294b38>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "early_stopping = EarlyStopping(monitor='val_loss', mode='auto', patience=100)\n",
    "model.fit(g, h,\n",
    "          batch_size=300,\n",
    "          epochs=1000,\n",
    "          shuffle=True,\n",
    "          validation_split=0.1,\n",
    "          callbacks=[early_stopping]\n",
    "          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(176, 25, 1) (176, 25, 1)\n",
      "(176, 25, 1) (176, 1)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 予測\n",
    "predicted = model.predict(g) # (176, 25, 1) -> (176, 25, 1) # t+1のデータを予測したものが176個。\n",
    "print(g.shape, predicted.shape)\n",
    "\n",
    "predicted = predicted[:,-1,0].reshape(-1,1)\n",
    "print(g.shape, predicted.shape)\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(range(0, len(f)), f, color=\"b\", label=\"predict_data\")\n",
    "plt.plot(range(25,len(predicted)+25),predicted, color=\"r\", label=\"row_data\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 悪化した()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 25)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "future_test = g[175].T # 1x25\n",
    "\n",
    "# 1つの学習データの時間の長さ -> 25\n",
    "time_length = future_test.shape[1] # 25\n",
    "# 未来の予測データを保存していく変数\n",
    "future_result = np.empty((0))\n",
    "\n",
    "print(future_test.shape) # (1, 25)\n",
    "\n",
    "# 未来予想\n",
    "for step2 in range(400):\n",
    "\n",
    "    test_data = np.reshape(future_test, (1, time_length, 1))\n",
    "    batch_predict = model.predict(test_data)[:,-1,0].reshape(-1,1) # 一番最後のフレームだけ使う\n",
    "\n",
    "    future_test = np.delete(future_test, 0)\n",
    "    future_test = np.append(future_test, batch_predict)\n",
    "\n",
    "    future_result = np.append(future_result, batch_predict)\n",
    "\n",
    "\n",
    "# sin波をプロット\n",
    "plt.figure()\n",
    "plt.plot(range(25,len(predicted)+25),predicted, color=\"r\", label=\"predict\")\n",
    "plt.plot(range(0, len(f)), f, color=\"b\", label=\"row\")\n",
    "plt.plot(range(0+len(f), len(future_result)+len(f)), future_result, color=\"g\", label=\"future\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
